{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EtOEt_LightGCN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOC20UFsYSevotwLFOV6PQO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zbiogg/LightGCN/blob/master/EtOEt_LightGCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "M3FwBGWM5nU2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCj6OHBtqs8U",
        "outputId": "5422f66f-b894-4d14-e4a8-cd7c5156cbc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorly\n",
            "  Downloading tensorly-0.7.0-py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorly) (1.21.6)\n",
            "Collecting nose\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[K     |████████████████████████████████| 154 kB 34.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from tensorly) (1.4.1)\n",
            "Installing collected packages: nose, tensorly\n",
            "Successfully installed nose-1.3.7 tensorly-0.7.0\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 5.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_sparse-0.6.13-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.13\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (750 kB)\n",
            "\u001b[K     |████████████████████████████████| 750 kB 5.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.1\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.4.tar.gz (407 kB)\n",
            "\u001b[K     |████████████████████████████████| 407 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.8)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.4-py3-none-any.whl size=616603 sha256=9110bf10c67b6f15c356fe546df6730dff6d9769cf5be15bde0178ac86a2e34e\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/a6/a4/ca18c3051fcead866fe7b85700ee2240d883562a1bc70ce421\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorly\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade ipython\n",
        "!pip install -q --upgrade ipykernel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rez3h1oduIgw",
        "outputId": "3bde243e-0294-4bb9-b9c0-ae9672361acf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 793 kB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 381 kB 43.4 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.29 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.33.0 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 131 kB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 130 kB 39.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 428 kB 44.9 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.29 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.13.0 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.33.0 which is incompatible.\n",
            "google-colab 1.0.0 requires tornado~=5.1.0; python_version >= \"3.0\", but you have tornado 6.1 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import math\n",
        "import os\n",
        "import os.path as osp\n",
        "from tqdm import tqdm\n",
        "from typing import List\n",
        "import random\n",
        "import time\n",
        "import zipfile\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.options.display.max_rows = 10\n",
        "from sklearn import metrics\n",
        "from tensorly import decomposition\n",
        "\n"
      ],
      "metadata": {
        "id": "b84tyJB7q1Jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.10.0+cu111 torchvision==0.11.0+cu111 torchaudio==0.10.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slmHHAMxvSKM",
        "outputId": "4ad8b49b-5a69-4d6a-d6b9-6c6f8f540921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.10.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2137.6 MB)\n",
            "\u001b[K     |████████████▌                   | 834.1 MB 1.8 MB/s eta 0:12:06tcmalloc: large alloc 1147494400 bytes == 0x399d8000 @  0x7febcd85a615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |███████████████▉                | 1055.7 MB 1.5 MB/s eta 0:11:39tcmalloc: large alloc 1434370048 bytes == 0x7e02e000 @  0x7febcd85a615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |████████████████████            | 1336.2 MB 1.4 MB/s eta 0:09:24tcmalloc: large alloc 1792966656 bytes == 0x2e60000 @  0x7febcd85a615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |█████████████████████████▎      | 1691.1 MB 1.4 MB/s eta 0:05:10tcmalloc: large alloc 2241208320 bytes == 0x6dc48000 @  0x7febcd85a615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |████████████████████████████████| 2137.6 MB 1.4 MB/s eta 0:00:01tcmalloc: large alloc 2137645056 bytes == 0xf35aa000 @  0x7febcd8591e7 0x4a3940 0x4a39cc 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9\n",
            "tcmalloc: large alloc 2672058368 bytes == 0x1e70cc000 @  0x7febcd85a615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576\n",
            "\u001b[K     |████████████████████████████████| 2137.6 MB 407 bytes/s \n",
            "\u001b[?25hCollecting torchvision==0.11.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.11.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (21.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.9 MB 1.4 MB/s \n",
            "\u001b[?25hCollecting torchaudio==0.10.0\n",
            "  Downloading https://download.pytorch.org/whl/rocm4.1/torchaudio-0.10.0%2Brocm4.1-cp37-cp37m-linux_x86_64.whl (2.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7 MB 35.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0+cu111) (4.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.0+cu111) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.0+cu111) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.12.0+cu113\n",
            "    Uninstalling torchvision-0.12.0+cu113:\n",
            "      Successfully uninstalled torchvision-0.12.0+cu113\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.11.0+cu113\n",
            "    Uninstalling torchaudio-0.11.0+cu113:\n",
            "      Successfully uninstalled torchaudio-0.11.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.10.0+cu111 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.10.0+cu111 torchaudio-0.10.0+rocm4.1 torchvision-0.11.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.functional import tensordot\n",
        "from torch import nn, optim, Tensor\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Dataset, Data, download_url, extract_zip\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.typing import Adj"
      ],
      "metadata": {
        "id": "BP0i0CsKu-XX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"PyTorch has version {torch.__version__}\")\n",
        "print(f\"Torch version: {torch.__version__}\")\n",
        "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
        "print(f\"Torch geometric version: {torch_geometric.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "131eE-FMwU8c",
        "outputId": "aa35c136-26fa-4599-ef94-bf5176ad2728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch has version 1.10.0+cu111\n",
            "Torch version: 1.10.0+cu111\n",
            "Cuda available: True\n",
            "Torch geometric version: 2.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config"
      ],
      "metadata": {
        "id": "QEZz7Vha6V_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rating_threshold = 3  #@param {type: \"integer\"}: Ratings equal to or greater than 3 are positive items.\n",
        "\n",
        "config_dict = {\n",
        "    \"num_samples_per_user\": 500,\n",
        "    \"num_users\": 200,\n",
        "\n",
        "    \"epochs\": 100,\n",
        "    \"batch_size\": 128,\n",
        "    \"lr\": 0.001,\n",
        "    \"weight_decay\": 0.1,\n",
        "\n",
        "    \"embedding_size\": 64,\n",
        "    \"num_layers\": 5,\n",
        "    \"K\": 10,\n",
        "    \"mf_rank\": 8,\n",
        "\n",
        "    \"minibatch_per_print\": 100,\n",
        "    \"epochs_per_print\": 1,\n",
        "\n",
        "    \"val_frac\": 0.2,\n",
        "    \"test_frac\": 0.1,\n",
        "\n",
        "    \"model_name\": \"model.pth\"\n",
        "}"
      ],
      "metadata": {
        "id": "QVMtihKHwXz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "4U30Watv6uoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"https://files.grouplens.org/datasets/movielens/ml-1m.zip\""
      ],
      "metadata": {
        "id": "y7rgd2XBwe2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trans_ml(dat, thres):\n",
        "    \"\"\"\n",
        "    Transform function that assign non-negative entries >= thres 1, and non-\n",
        "    negative entries <= thres 0. Keep other entries the same.\n",
        "    \"\"\"\n",
        "    thres = thres[0]\n",
        "    matrix = dat['edge_index']\n",
        "    matrix[(matrix < thres) & (matrix > -1)] = 0\n",
        "    matrix[(matrix >= thres)] = 1\n",
        "    dat['edge_index'] = matrix\n",
        "    return dat\n",
        "\n",
        "\n",
        "class MovieLens(Dataset):\n",
        "    def __init__(self, root, transform=None, pre_transform=None,\n",
        "            transform_args=None, pre_transform_args=None):\n",
        "        \"\"\"\n",
        "        root = where the dataset should be stored. This folder is split\n",
        "        into raw_dir (downloaded dataset) and processed_dir (process data).\n",
        "        \"\"\"\n",
        "        super(MovieLens, self).__init__(root, transform, pre_transform)\n",
        "        self.transform = transform\n",
        "        self.pre_transform = pre_transform\n",
        "        self.transform_args = transform_args\n",
        "        self.pre_transform_args = pre_transform_args\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return \"ml-1m.zip\"\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return [\"data_movielens.pt\"]\n",
        "\n",
        "    def download(self):\n",
        "        # Download to `self.raw_dir`.\n",
        "        download_url(DATA_PATH, self.raw_dir)\n",
        "\n",
        "    def _load(self):\n",
        "        print(self.raw_dir)\n",
        "        # extract_zip(self.raw_paths[0], self.raw_dir)\n",
        "        with zipfile.ZipFile(self.raw_paths[0], 'r') as zip_ref:\n",
        "            zip_ref.extractall(self.raw_dir)\n",
        "        unames = ['user_id', 'gender', 'age', 'occupation', 'zip']\n",
        "        users = pd.read_table(self.raw_dir+'/ml-1m/users.dat', \n",
        "                              sep='::', header=None, names=unames,\n",
        "                              engine='python', encoding='latin-1')\n",
        "        rnames = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
        "        ratings = pd.read_table(self.raw_dir+'/ml-1m/ratings.dat', sep='::', \n",
        "                                header=None, names=rnames, engine='python',\n",
        "                                encoding='latin-1')\n",
        "        mnames = ['movie_id', 'title', 'genres']\n",
        "        movies = pd.read_table(self.raw_dir+'/ml-1m/movies.dat', sep='::', \n",
        "                               header=None, names=mnames, engine='python',\n",
        "                               encoding='latin-1')\n",
        "        dat = pd.merge(pd.merge(ratings, users), movies)\n",
        "\n",
        "        return users, ratings, movies, dat\n",
        "\n",
        "    def process(self):\n",
        "        print('run process')\n",
        "        # load information from file\n",
        "        users, ratings, movies, dat = self._load()\n",
        "\n",
        "        users = users['user_id']\n",
        "        movies = movies['movie_id']\n",
        "\n",
        "        num_users = config_dict[\"num_users\"]\n",
        "        if num_users != -1:\n",
        "            users = users[:num_users]\n",
        "\n",
        "        user_ids = range(len(users))\n",
        "        movie_ids = range(len(movies))\n",
        "\n",
        "        user_to_id = dict(zip(users, user_ids))\n",
        "        movie_to_id = dict(zip(movies, movie_ids))\n",
        "\n",
        "        # lấy các thông tin gần kề\n",
        "        self.num_user = users.shape[0]\n",
        "        self.num_item = movies.shape[0]\n",
        "\n",
        "        # khởi tạo ma trận kề\n",
        "        rat = torch.zeros(self.num_user, self.num_item)\n",
        "\n",
        "        for index, row in ratings.iterrows():\n",
        "            user, movie, rating = row[:3]\n",
        "            if num_users != -1:\n",
        "                if user not in user_to_id: break\n",
        "            # tạo ma trận raking trong đó đầu vào (i, j) đại diện cho xếp hạng\n",
        "            # của phim j do người dùng i đưa ra.\n",
        "            rat[user_to_id[user], movie_to_id[movie]] = rating\n",
        "\n",
        "        # khởi tạo Data object\n",
        "        data = Data(edge_index = rat,\n",
        "                    raw_edge_index = rat.clone(),\n",
        "                    data = ratings,\n",
        "                    users = users,\n",
        "                    items = movies)\n",
        "\n",
        "        # apply any pre-transformation\n",
        "        if self.pre_transform is not None:\n",
        "            data = self.pre_transform(data, self.pre_transform_args)\n",
        "\n",
        "        # apply any post_transformation\n",
        "        # if self.transform is not None:\n",
        "        #     # data = self.transform(data, self.transform_args)\n",
        "        data = self.transform(data, [rating_threshold])\n",
        "\n",
        "        # lưu dữ liệu đã xử lý vào file data_movielens.pt\n",
        "        torch.save(data, osp.join(self.processed_dir, f'data_movielens.pt'))\n",
        "        print('process finished')\n",
        "      \n",
        "    def len(self):\n",
        "        \"\"\"\n",
        "        return the number of examples in your graph\n",
        "        \"\"\"\n",
        "        # TODO: how to define number of examples\n",
        "        return \n",
        "\n",
        "    def get(self):\n",
        "        \"\"\"\n",
        "        Logic tải biểu đồ duy nhất\n",
        "        \"\"\"\n",
        "        data = torch.load(osp.join(self.processed_dir, 'data_movielens.pt'))\n",
        "        return data\n",
        "\n",
        "    def train_val_test_split(self, val_frac=0.2, test_frac=0.1):\n",
        "        \"\"\"\n",
        "        Trả về 2 ma trận mask (M,N) đại diện cho các cạnh có trong tập train và val\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.num_user, self.num_item\n",
        "        except AttributeError:\n",
        "            data = self.get()\n",
        "            self.num_user = len(data[\"users\"].unique())\n",
        "            self.num_item = len(data[\"items\"].unique())\n",
        "        # Lấy số lượng các cạnh mask để train và validation\n",
        "        num_train_replaced = \\\n",
        "            round((test_frac+val_frac)*self.num_user*self.num_item)\n",
        "        num_val_show = round(val_frac*self.num_user*self.num_item)\n",
        "\n",
        "        # cách cạnh mask trong quá trình train\n",
        "        indices_user = np.random.randint(0, self.num_user, num_train_replaced)\n",
        "        indices_item = np.random.randint(0, self.num_item, num_train_replaced)\n",
        "        \n",
        "        # sample part of edges from training stage to be unmasked during\n",
        "        # validation\n",
        "        indices_val_user = np.random.choice(indices_user, num_val_show)\n",
        "        indices_val_item = np.random.choice(indices_item, num_val_show)\n",
        "\n",
        "        train_mask = torch.ones(self.num_user, self.num_item)\n",
        "        train_mask[indices_user, indices_item] = 0\n",
        "\n",
        "        val_mask = train_mask.clone()\n",
        "        val_mask[indices_val_user, indices_val_item] = 1\n",
        "\n",
        "        test_mask = torch.ones_like(train_mask)\n",
        "\n",
        "        return train_mask, val_mask, test_mask"
      ],
      "metadata": {
        "id": "ZM_H-BTqwiZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement LightGCN"
      ],
      "metadata": {
        "id": "8WOtodFB7HIX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LightGCN neighborhood aggregation layer"
      ],
      "metadata": {
        "id": "0K9BAesv7emc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LightGCNConv(MessagePassing):\n",
        "    r\"\"\"The neighbor aggregation operator from the `\"LightGCN: Simplifying and\n",
        "    Powering Graph Convolution Network for Recommendation\"\n",
        "    <https://arxiv.org/abs/2002.02126#>`_ paper\n",
        "\n",
        "    Args:\n",
        "        in_channels (int): Size of each input sample, or :obj:`-1` to derive\n",
        "            the size from the first input(s) to the forward method.\n",
        "        out_channels (int): Size of each output sample.\n",
        "        num_users (int): Number of users for recommendation.\n",
        "        num_items (int): Number of items to recommend.\n",
        "        **kwargs (optional): Additional arguments of\n",
        "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels: int, out_channels: int,\n",
        "                 num_users: int, num_items: int, **kwargs):\n",
        "        super(LightGCNConv, self).__init__(**kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        pass  # There are no layer parameters to learn.\n",
        "\n",
        "    def forward(self, x: Tensor, edge_index: Adj) -> Tensor:\n",
        "        \"\"\"Performs neighborhood aggregation for user/item embeddings.\"\"\"\n",
        "        user_item = \\\n",
        "                torch.zeros(self.num_users, self.num_items, device=x.device)\n",
        "        user_item[edge_index[:, 0], edge_index[:, 1]] = 1\n",
        "        user_neighbor_counts = torch.sum(user_item, axis=1)\n",
        "        item_neightbor_counts = torch.sum(user_item, axis=0)\n",
        "        # Compute weight for aggregation: 1 / sqrt(N_u * N_i)\n",
        "        weights = user_item / torch.sqrt(\n",
        "                user_neighbor_counts.repeat(self.num_items, 1).T \\\n",
        "                * item_neightbor_counts.repeat(self.num_users, 1))\n",
        "        weights = torch.nan_to_num(weights, nan=0)\n",
        "        out = torch.concat((weights.T @ x[:self.num_users],\n",
        "                            weights @ x[self.num_users:]), 0)\n",
        "        return out\n",
        "\n",
        "    def __repr__(self):\n",
        "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels,\n",
        "                                   self.out_channels)\n"
      ],
      "metadata": {
        "id": "Ure-D-3gwlcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LightGCN model"
      ],
      "metadata": {
        "id": "tDdrSBj27mVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LightGCN(nn.Module):\n",
        "    def __init__(self, \n",
        "                 config: dict,\n",
        "                 device=None,\n",
        "                 **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_users  = config[\"n_users\"]\n",
        "        self.num_items  = config[\"m_items\"]\n",
        "        self.embedding_size = config[\"embedding_size\"]\n",
        "        self.in_channels = self.embedding_size\n",
        "        self.out_channels = self.embedding_size\n",
        "        self.num_layers = config[\"num_layers\"]\n",
        "\n",
        "        # 0-th layer embedding.\n",
        "        self.embedding_user_item = torch.nn.Embedding(\n",
        "            num_embeddings=self.num_users + self.num_items,\n",
        "            embedding_dim=self.embedding_size)\n",
        "        self.alpha = None\n",
        "\n",
        "        # random normal init seems to be a better choice when lightGCN actually\n",
        "        # don't use any non-linear activation function\n",
        "        nn.init.normal_(self.embedding_user_item.weight, std=0.1)\n",
        "        print('use NORMAL distribution initilizer')\n",
        "\n",
        "        self.f = nn.Sigmoid()\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.convs.append(LightGCNConv(\n",
        "                self.embedding_size, self.embedding_size,\n",
        "                num_users=self.num_users, num_items=self.num_items, **kwargs))\n",
        "\n",
        "        for _ in range(1, self.num_layers):\n",
        "            self.convs.append(\n",
        "                LightGCNConv(\n",
        "                        self.embedding_size, self.embedding_size, \n",
        "                        num_users=self.num_users, num_items=self.num_items,\n",
        "                        **kwargs))\n",
        "\n",
        "        self.device = None\n",
        "        if device is not None:\n",
        "            self.convs.to(device)\n",
        "            self.device = device\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "\n",
        "    def forward(self, x: Tensor, edge_index: Adj, *args, **kwargs) -> Tensor:\n",
        "        xs: List[Tensor] = []\n",
        "\n",
        "        edge_index = torch.nonzero(edge_index)\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.convs[i](x, edge_index, *args, **kwargs)\n",
        "            if self.device is not None:\n",
        "                x = x.to(self.device)\n",
        "            xs.append(x)\n",
        "        xs = torch.stack(xs)\n",
        "        \n",
        "        self.alpha = 1 / (1 + self.num_layers) * torch.ones(xs.shape)\n",
        "        if self.device is not None:\n",
        "            self.alpha = self.alpha.to(self.device)\n",
        "            xs = xs.to(self.device)\n",
        "        x = (xs * self.alpha).sum(dim=0)  # Sum along K layers.\n",
        "        return x\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
        "                f'{self.out_channels}, num_layers={self.num_layers})')"
      ],
      "metadata": {
        "id": "Ik7B9lauws-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "HLFmBJqj6Dys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getUsersRating(model, users, data):\n",
        "    \"\"\" Get the embedding of users\n",
        "    INPUT:\n",
        "        model: the LightGCN model you are training on\n",
        "        users: this is the user index (note: use 0-indexed and not user number,\n",
        "            which is 1-indexed)\n",
        "        data: the entire data, used to fetch all users and all items\n",
        "    \"\"\"\n",
        "    all_users_items = model(model.embedding_user_item.weight.clone(),\n",
        "                            data[\"edge_index\"])\n",
        "    all_users = all_users_items[:len(data[\"users\"])]\n",
        "    items_emb = all_users_items[len(data[\"users\"]):]\n",
        "    users_emb = all_users[users.long()]\n",
        "    rating = model.f(torch.matmul(users_emb, items_emb.t()))\n",
        "    return rating\n",
        "\n",
        "def getEmbedding(model, users, pos, neg, data, mask):\n",
        "    \"\"\"\n",
        "    INPUT:\n",
        "        model: the LightGCN model you are training on\n",
        "        users: this is the user index (note: use 0-indexed and not user number,\n",
        "            which is 1-indexed)\n",
        "        pos: positive index corresponding to an item that the user like\n",
        "        neg: negative index corresponding to an item that the user doesn't like\n",
        "        data: the entire data, used to fetch all users and all items\n",
        "        mask: Masking matrix indicating edges present in the current\n",
        "            train / validation / test set.\n",
        "    \"\"\"\n",
        "    # assuming we always search for users and items by their indices (instead of\n",
        "    # user/item number)\n",
        "    all_users_items = model(model.embedding_user_item.weight.clone(),\n",
        "                            data[\"edge_index\"] * mask)\n",
        "    all_users = all_users_items[:len(data[\"users\"])]\n",
        "    all_items = all_users_items[len(data[\"users\"]):]\n",
        "    users_emb = all_users[users]\n",
        "    pos_emb = all_items[pos]\n",
        "    neg_emb = all_items[neg]\n",
        "    n_user = len(data[\"users\"])\n",
        "    users_emb_ego = model.embedding_user_item(users)\n",
        "    # offset the index to fetch embedding from user_item\n",
        "    pos_emb_ego = model.embedding_user_item(pos + n_user)\n",
        "    neg_emb_ego = model.embedding_user_item(neg + n_user)\n",
        "    return users_emb, pos_emb, neg_emb, users_emb_ego, pos_emb_ego, neg_emb_ego"
      ],
      "metadata": {
        "id": "Owzz7oRTwuw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BPR Loss\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xKcv9_mu8Y-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bpr_loss(model, users, pos, neg, data, mask):\n",
        "    \"\"\" \n",
        "    INPUT:\n",
        "        model: the LightGCN model you are training on\n",
        "        users: this is the user index (note: use 0-indexed and not user number,\n",
        "            which is 1-indexed)\n",
        "        pos: positive index corresponding to an item that the user like\n",
        "            (0-indexed, note to index items starting from 0)\n",
        "        neg: negative index corresponding to an item that the user doesn't like\n",
        "        data: the entire data, used to fetch all users and all items\n",
        "        mask: Masking matrix indicating edges present in the current\n",
        "            train / validation / test set.\n",
        "    OUTPUT:\n",
        "        loss, reg_loss\n",
        "    \"\"\"\n",
        "    # assuming we always sample the same number of positive and negative sample\n",
        "    # per user\n",
        "    assert len(users) == len(pos) and len(users) == len(neg)\n",
        "    (users_emb, pos_emb, neg_emb, \n",
        "    userEmb0,  posEmb0, negEmb0) = getEmbedding(model, users.long(), pos.long(),\n",
        "                                                neg.long(), data, mask)\n",
        "    reg_loss = (1/2)*(userEmb0.norm(2).pow(2) + \n",
        "                        posEmb0.norm(2).pow(2)  +\n",
        "                        negEmb0.norm(2).pow(2))/float(len(users))\n",
        "    pos_scores = torch.mul(users_emb, pos_emb)\n",
        "    pos_scores = torch.sum(pos_scores, dim=1)\n",
        "    neg_scores = torch.mul(users_emb, neg_emb)\n",
        "    neg_scores = torch.sum(neg_scores, dim=1)\n",
        "    \n",
        "    loss = torch.mean(torch.nn.functional.softplus(neg_scores - pos_scores))\n",
        "    \n",
        "    return loss, reg_loss"
      ],
      "metadata": {
        "id": "gtlWZHbmwyEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Personalized top K precision and recall"
      ],
      "metadata": {
        "id": "KDOiN5dh960c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def personalized_topk(pred, K, user_indices, edge_index):\n",
        "    \"\"\"Computes TopK precision and recall.\n",
        "\n",
        "    Args:\n",
        "        pred: Predicted similarities between user and item.\n",
        "        K: Number of items to rank.\n",
        "        user_indices: Indices of users for each prediction in `pred`.\n",
        "        edge_index: User and item connection matrix.\n",
        "\n",
        "    Returns:\n",
        "        Average Top K precision and recall for users in `user_indices`.\n",
        "    \"\"\"\n",
        "    per_user_preds = collections.defaultdict(list)\n",
        "    for index, user in enumerate(user_indices):\n",
        "        per_user_preds[user.item()].append(pred[index].item())\n",
        "    precisions = 0.0\n",
        "    recalls = 0.0\n",
        "    for user, preds in per_user_preds.items():\n",
        "        while len(preds) < K:\n",
        "            preds.append(random.choice(range(edge_index.shape[1])))\n",
        "        top_ratings, top_items = torch.topk(torch.tensor(preds), K)\n",
        "        correct_preds = edge_index[user, top_items].sum().item()\n",
        "        total_pos = edge_index[user].sum().item()\n",
        "        precisions += correct_preds / K\n",
        "        recalls += correct_preds / total_pos if total_pos != 0 else 0\n",
        "    num_users = len(user_indices.unique())\n",
        "    return precisions / num_users, recalls / num_users"
      ],
      "metadata": {
        "id": "7V0z1Xs9w0Ed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ..."
      ],
      "metadata": {
        "id": "JdtPn4p_GbEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _sample_pos_neg(data, mask, num_samples_per_user):\n",
        "    \"\"\"Samples (user, positive item, negative item) tuples per user.\n",
        "\n",
        "    If a user does not have a postive (negative) item, we choose an item\n",
        "    with unknown liking (an item without raw rating data).\n",
        "\n",
        "    Args:\n",
        "        data: Dataset object containing edge_index and raw ratings matrix.\n",
        "        mask: Masking matrix indicating edges present in the current\n",
        "            train / validation / test set.\n",
        "        num_samples_per_user: Number of samples to generate for each user.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor object of (user, positive item, negative item) samples.\n",
        "    \"\"\"\n",
        "    print(\"=====Starting to sample=====\")\n",
        "    start = time.time()\n",
        "    samples = []\n",
        "    all_items = set(range(len(data[\"items\"])))\n",
        "    for user_index, user in enumerate(data[\"users\"]):\n",
        "        pos_items = set(\n",
        "            torch.nonzero(data[\"edge_index\"][user_index])[:, 0].tolist())\n",
        "        unknown_items = all_items.difference(\n",
        "                set(\n",
        "                    torch.nonzero(\n",
        "                        data[\"raw_edge_index\"][user_index])[:, 0].tolist()))\n",
        "        neg_items = all_items.difference(\n",
        "            set(pos_items)).difference(set(unknown_items))\n",
        "        unmasked_items = set(torch.nonzero(mask[user_index])[:, 0].tolist())\n",
        "        if len(unknown_items.union(pos_items)) == 0 or \\\n",
        "                len(unknown_items.union(neg_items)) == 0:\n",
        "            continue\n",
        "        for _ in range(num_samples_per_user):\n",
        "            if len(pos_items.intersection(unmasked_items)) == 0:\n",
        "                pos_item_index = random.choice(\n",
        "                    list(unknown_items.intersection(unmasked_items)))\n",
        "            else:\n",
        "                pos_item_index = random.choice(\n",
        "                    list(pos_items.intersection(unmasked_items)))\n",
        "            if len(neg_items.intersection(unmasked_items)) == 0:\n",
        "                neg_item_index = random.choice(\n",
        "                    list(unknown_items.intersection(unmasked_items)))\n",
        "            else:\n",
        "                neg_item_index = random.choice(\n",
        "                    list(neg_items.intersection(unmasked_items)))\n",
        "            samples.append((user_index, pos_item_index, neg_item_index))\n",
        "    end = time.time()\n",
        "    print(f\"=====Sampling completed (took {end - start} seconds)=====\")\n",
        "    return torch.tensor(samples, dtype=torch.int32)\n",
        "\n",
        "def sample_pos_neg(data, train_mask, val_mask, test_mask, num_samples_per_user):\n",
        "    \"\"\"Samples (user, positive item, negative item) tuples per user.\n",
        "\n",
        "    If a user does not have a postive (negative) item, we choose an item\n",
        "    with unknown liking (an item without raw rating data).\n",
        "\n",
        "    Args:\n",
        "        data: Dataset object containing edge_index and raw ratings matrix.\n",
        "        train_mask: Masking matrix indicating edges present in train set.\n",
        "        val_mask: Masking matrix indicating edges present in validation set.\n",
        "        test_mask: Masking matrix indicating edges present in test set.\n",
        "        num_samples_per_user: Number of samples to generate for each user.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor object of (user, positive item, negative item) samples for\n",
        "        train, validation and test.\n",
        "    \"\"\"\n",
        "    train_samples = _sample_pos_neg(data, train_mask, num_samples_per_user)\n",
        "    val_samples = _sample_pos_neg(data, val_mask, num_samples_per_user)\n",
        "    test_samples = _sample_pos_neg(data, test_mask, num_samples_per_user)\n",
        "    return train_samples, val_samples, test_samples"
      ],
      "metadata": {
        "id": "_sgcXHvZw5Kk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "root = os.getcwd()\n",
        "movielens = MovieLens(root=root, transform=trans_ml)\n",
        "data = movielens.get()\n",
        "train_mask, val_mask, test_mask = \\\n",
        "        movielens.train_val_test_split(val_frac=config_dict[\"val_frac\"],\n",
        "                                       test_frac=config_dict[\"test_frac\"])\n",
        "\n",
        "n_users = len(data[\"users\"].unique())\n",
        "m_items = len(data[\"items\"].unique())\n",
        "print(f\"#Users: {n_users}\")\n",
        "print(f\"#Items: {m_items}\")\n",
        "\n",
        "model_config = {\n",
        "    \"n_users\": n_users,\n",
        "    \"m_items\": m_items,\n",
        "    \"embedding_size\": config_dict[\"embedding_size\"],\n",
        "    \"num_layers\": config_dict[\"num_layers\"],\n",
        "}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "lightGCN = LightGCN(model_config, device=device)\n",
        "\n",
        "num_samples_per_user = config_dict[\"num_samples_per_user\"]\n",
        "epochs = config_dict[\"epochs\"]\n",
        "batch_size = config_dict[\"batch_size\"]\n",
        "lr = config_dict[\"lr\"]\n",
        "weight_decay = config_dict[\"weight_decay\"]\n",
        "\n",
        "K = config_dict[\"K\"]\n",
        "\n",
        "lightGCN.to(device)\n",
        "\n",
        "samples_train, samples_val, samples_test = \\\n",
        "        sample_pos_neg(data, train_mask, val_mask, test_mask,\n",
        "                       num_samples_per_user)\n",
        "\n",
        "samples_train=samples_train.to(device)\n",
        "samples_val=samples_val.to(device)\n",
        "samples_test=samples_test.to(device)\n",
        "train_mask=train_mask.to(device)\n",
        "val_mask=val_mask.to(device)\n",
        "test_mask=test_mask.to(device)\n",
        "data = data.to(device)\n",
        "\n",
        "print(f\"#Training samples: {len(samples_train)}\",\n",
        "      f\"#Validation samples: {len(samples_val)}\",\n",
        "      f\"#Test samples: {len(samples_test)}\")\n",
        "\n",
        "optimizer = optim.Adam(lightGCN.parameters(), lr=lr)\n",
        "print(\"Optimizer:\", optimizer)\n",
        "\n",
        "epochs_tracked = []\n",
        "train_topks = []\n",
        "val_topks = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(\"Training on the {} epoch\".format(epoch))\n",
        "    lightGCN.train()\n",
        "    loss_sum = 0\n",
        "    # Shuffle the order of rows.\n",
        "    samples_train = samples_train[torch.randperm(samples_train.size()[0])]\n",
        "    for batch_idx in range(math.ceil(len(samples_train) / batch_size)):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        current_batch = \\\n",
        "            samples_train[batch_idx*batch_size: (batch_idx+1)*batch_size]\n",
        "        # Shuffle the order of rows.\n",
        "        current_batch = current_batch[torch.randperm(current_batch.size()[0])]\n",
        "        users = current_batch[:, 0:1]\n",
        "        pos = current_batch[:, 1:2]\n",
        "        neg = current_batch[:, 2:3]\n",
        "\n",
        "        loss, reg_loss = bpr_loss(lightGCN, users, pos, neg, data,\n",
        "                                  train_mask)\n",
        "        reg_loss = reg_loss * weight_decay\n",
        "        loss = loss + reg_loss\n",
        "        loss_sum += loss.detach()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % config_dict[\"minibatch_per_print\"] == 0:\n",
        "            all_users = torch.linspace(start=0,\n",
        "                                       end=n_users - 1, steps=n_users).long()\n",
        "            user_indices = current_batch[:, 0]\n",
        "            user_indices = user_indices.repeat(2).long()\n",
        "            item_indices = torch.cat(\n",
        "                (current_batch[:, 1], current_batch[:, 2])).long()\n",
        "            pred = getUsersRating(lightGCN,\n",
        "                                  all_users,\n",
        "                                  data)[user_indices, item_indices]\n",
        "            truth = data[\"edge_index\"][user_indices, item_indices]\n",
        "            topk_precision, topk_recall = \\\n",
        "                personalized_topk(pred, K, user_indices, data[\"edge_index\"])\n",
        "\n",
        "            print(\"Training on epoch {} minibatch {}/{} completed\\n\".format(epoch, batch_idx+1,\n",
        "                                                                            math.ceil(len(samples_train) / batch_size)),\n",
        "                  \"bpr_loss on current minibatch is {}, and regularization loss is {}.\\n\".format(round(float(loss.detach().cpu()), 6),\n",
        "                                                                                                 round(float(reg_loss.detach().cpu()), 6)),\n",
        "                  \"Top K precision = {}, recall = {}.\".format(topk_precision, topk_recall))\n",
        "\n",
        "    if epoch % config_dict[\"epochs_per_print\"] == 0:\n",
        "        epochs_tracked.append(epoch)\n",
        "\n",
        "        # evaluation on both the trainisng and validation set\n",
        "        lightGCN.eval()\n",
        "        # predict on the training set\n",
        "        users = samples_train[:, 0:1]\n",
        "        user_indices = samples_train[:, 0]\n",
        "        user_indices = user_indices.repeat(2).long()\n",
        "        item_indices = torch.cat(\n",
        "            (samples_train[:, 1], samples_train[:, 2])).long()\n",
        "        pred = getUsersRating(lightGCN,\n",
        "                              users[:,0],\n",
        "                              data)[user_indices, item_indices]\n",
        "        truth = data[\"edge_index\"][users.long()[:,0]]\\\n",
        "            [user_indices, item_indices]\n",
        "        train_topk_precision, train_topk_recall = \\\n",
        "            personalized_topk(pred, K, user_indices, data[\"edge_index\"])\n",
        "        train_topks.append((train_topk_precision, train_topk_recall))\n",
        "\n",
        "        # predict on the validation set\n",
        "        users_val = samples_val[:, 0:1]\n",
        "        pos_val = samples_val[:, 1:2]\n",
        "        neg_val = samples_val[:, 2:3]\n",
        "\n",
        "        loss_val, reg_loss_val = bpr_loss(\n",
        "            lightGCN, users_val, pos_val, neg_val, data, val_mask)\n",
        "        reg_loss_val = reg_loss_val * weight_decay\n",
        "\n",
        "        # predict on the validation set\n",
        "        user_indices = samples_val[:, 0]\n",
        "        user_indices = user_indices.repeat(2).long()\n",
        "        item_indices = torch.cat((samples_val[:, 1], samples_val[:, 2])).long()\n",
        "        pred_val = getUsersRating(lightGCN,\n",
        "                                  users_val[:,0],\n",
        "                                  data)[user_indices, item_indices]\n",
        "        truth_val = data[\"edge_index\"][users_val.long()[:,0]]\\\n",
        "            [user_indices, item_indices]\n",
        "        val_topk_precision, val_topk_recall = \\\n",
        "            personalized_topk(pred_val, K, user_indices, data[\"edge_index\"])\n",
        "        val_topks.append((val_topk_precision, val_topk_recall))\n",
        "\n",
        "        print(\"\\nTraining on {} epoch completed.\\n\".format(epoch),\n",
        "              \"Average bpr_loss on train set is {} for the current epoch.\\n\".format(round(float(loss_sum/len(samples_train)), 6)),\n",
        "              \"Training top K precision = {}, recall = {}.\\n\".format(train_topk_precision, train_topk_recall),\n",
        "              \"Average bpr_loss on the validation set is {}, and regularization loss is {}.\\n\".format(round(float((loss_val+reg_loss_val)/len(samples_val)), 6),\n",
        "                                                                                                      round(float(reg_loss_val/len(samples_val)), 6)),\n",
        "              \"Validation top K precision = {}, recall = {}.\\n\".format(val_topk_precision, val_topk_recall))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyDcEzADw7Hh",
        "outputId": "8d11cfcd-9270-430c-f5aa-7b2c219c2aad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run process\n",
            "/content/raw\n",
            "process finished\n",
            "#Users: 200\n",
            "#Items: 3883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "use NORMAL distribution initilizer\n",
            "=====Starting to sample=====\n",
            "=====Sampling completed (took 2.9179184436798096 seconds)=====\n",
            "=====Starting to sample=====\n",
            "=====Sampling completed (took 2.948317527770996 seconds)=====\n",
            "=====Starting to sample=====\n",
            "=====Sampling completed (took 2.8732337951660156 seconds)=====\n",
            "#Training samples: 100000 #Validation samples: 100000 #Test samples: 100000\n",
            "Optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.001\n",
            "    weight_decay: 0\n",
            ")\n",
            "Training on the 0 epoch\n",
            "Training on epoch 0 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.789179, and regularization loss is 0.096032.\n",
            " Top K precision = 0.07849462365591398, recall = 0.006392405361561284.\n",
            "Training on epoch 0 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.73963, and regularization loss is 0.046482.\n",
            " Top K precision = 0.08421052631578943, recall = 0.0060061346729823155.\n",
            "Training on epoch 0 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.717478, and regularization loss is 0.024331.\n",
            " Top K precision = 0.08043478260869563, recall = 0.009284691812906351.\n",
            "Training on epoch 0 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.707955, and regularization loss is 0.014807.\n",
            " Top K precision = 0.09325842696629211, recall = 0.007174166968393228.\n",
            "Training on epoch 0 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.70093, and regularization loss is 0.007783.\n",
            " Top K precision = 0.07448979591836735, recall = 0.007470573043498166.\n",
            "Training on epoch 0 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.699274, and regularization loss is 0.006127.\n",
            " Top K precision = 0.07849462365591398, recall = 0.007541633973998806.\n",
            "Training on epoch 0 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.696986, and regularization loss is 0.003839.\n",
            " Top K precision = 0.08749999999999995, recall = 0.007953712155427351.\n",
            "Training on epoch 0 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.695902, and regularization loss is 0.002754.\n",
            " Top K precision = 0.08681318681318681, recall = 0.008002239410572534.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tcmalloc: large alloc 1553203200 bytes == 0x134c0000 @  0x7fc87ba26b6b 0x7fc87ba46379 0x7fc762750cde 0x7fc762752452 0x7fc7b43b1ab9 0x7fc7b43b2817 0x7fc7b47f4dc9 0x7fc7b4ee07b3 0x7fc7b4f167e2 0x7fc7b4631a18 0x7fc7b4ee4c37 0x7fc7b4ee4c8f 0x7fc7b4d310d4 0x7fc7b4d31442 0x7fc7b65c684f 0x7fc7b65c7432 0x7fc7b4d72086 0x7fc7b4640172 0x7fc7b464096a 0x7fc7b50564ef 0x7fc7b4e32956 0x7fc85dd7a57d 0x593784 0x548c51 0x51566f 0x593dd7 0x5118f8 0x549576 0x604173 0x62a809 0x59358d\n",
            "tcmalloc: large alloc 1553203200 bytes == 0x7041a000 @  0x7fc87ba26b6b 0x7fc87ba46379 0x7fc762750cde 0x7fc762752452 0x7fc7b43b1ab9 0x7fc7b43b2817 0x7fc7b47f4dc9 0x7fc7b4ee07b3 0x7fc7b4f1715f 0x7fc7b4399dff 0x7fc7b439de4d 0x7fc7b439ef48 0x7fc7b4f048b3 0x7fc7b4f0493c 0x7fc7b4b6a0df 0x7fc7b4b6b06e 0x7fc7b64a6e0f 0x7fc7b64a73df 0x7fc7b4ba341d 0x7fc85dd62c84 0x593784 0x548c51 0x51566f 0x4bc98a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bcb19 0x532e76 0x594b72\n",
            "tcmalloc: large alloc 1553203200 bytes == 0x134c0000 @  0x7fc87ba26b6b 0x7fc87ba46379 0x7fc762750cde 0x7fc762752452 0x7fc7b43b1ab9 0x7fc7b43b2817 0x7fc7b47f4dc9 0x7fc7b4ed844a 0x7fc7b4eb68fe 0x7fc7b4bbed60 0x7fc7b439ba05 0x7fc7b439cc5b 0x7fc7b439dfa3 0x7fc7b47d927e 0x7fc7b47dc714 0x7fc7b4ed938f 0x7fc7b4c4e84d 0x7fc7b6487a37 0x7fc7b6488092 0x7fc7b4ca607d 0x7fc85e136064 0x4d3969 0x512147 0x549576 0x604173 0x62a809 0x59358d 0x515244 0x598ef4 0x515a6e 0x598ef4\n",
            "tcmalloc: large alloc 1553203200 bytes == 0xdb114000 @  0x7fc87ba26b6b 0x7fc87ba46379 0x7fc762750cde 0x7fc762752452 0x7fc7b43b1ab9 0x7fc7b43b2817 0x7fc7b47f4dc9 0x7fc7b4ee07b3 0x7fc7b4f167e2 0x7fc7b4631a18 0x7fc7b4ee4c37 0x7fc7b4ee4c8f 0x7fc7b4d310d4 0x7fc7b4d31442 0x7fc7b65c684f 0x7fc7b65c7432 0x7fc7b4d72086 0x7fc7b4640172 0x7fc7b464096a 0x7fc7b50564ef 0x7fc7b4e32956 0x7fc85dd7a57d 0x593784 0x548c51 0x51566f 0x593dd7 0x5118f8 0x549576 0x604173 0x62a809 0x59358d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training on 0 epoch completed.\n",
            " Average bpr_loss on train set is 0.005571 for the current epoch.\n",
            " Training top K precision = 0.05699999999999993, recall = 0.005701996951026386.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.03999999999999999, recall = 0.004289893095680055.\n",
            "\n",
            "Training on the 1 epoch\n",
            "Training on epoch 1 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.696021, and regularization loss is 0.002874.\n",
            " Top K precision = 0.09285714285714286, recall = 0.006999704996855798.\n",
            "Training on epoch 1 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.695055, and regularization loss is 0.001908.\n",
            " Top K precision = 0.09801980198019797, recall = 0.0092365617862947.\n",
            "Training on epoch 1 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.694915, and regularization loss is 0.001768.\n",
            " Top K precision = 0.085, recall = 0.00643206834651088.\n",
            "Training on epoch 1 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.694274, and regularization loss is 0.001127.\n",
            " Top K precision = 0.07395833333333335, recall = 0.00713733251410845.\n",
            "Training on epoch 1 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.694305, and regularization loss is 0.001158.\n",
            " Top K precision = 0.08181818181818179, recall = 0.007688019683212417.\n",
            "Training on epoch 1 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.694107, and regularization loss is 0.00096.\n",
            " Top K precision = 0.09560439560439556, recall = 0.008316951787166302.\n",
            "Training on epoch 1 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.694422, and regularization loss is 0.001274.\n",
            " Top K precision = 0.08299999999999999, recall = 0.007487442965053182.\n",
            "Training on epoch 1 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.694374, and regularization loss is 0.001227.\n",
            " Top K precision = 0.08636363636363636, recall = 0.005960880093171119.\n",
            "\n",
            "Training on 1 epoch completed.\n",
            " Average bpr_loss on train set is 0.00543 for the current epoch.\n",
            " Training top K precision = 0.08899999999999991, recall = 0.007558772127474779.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 2 epoch\n",
            "Training on epoch 2 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693663, and regularization loss is 0.000516.\n",
            " Top K precision = 0.08404255319148933, recall = 0.006700374692411272.\n",
            "Training on epoch 2 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693385, and regularization loss is 0.000238.\n",
            " Top K precision = 0.0858585858585858, recall = 0.006969464634400904.\n",
            "Training on epoch 2 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693434, and regularization loss is 0.000286.\n",
            " Top K precision = 0.09120879120879113, recall = 0.007647552000733094.\n",
            "Training on epoch 2 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693535, and regularization loss is 0.000387.\n",
            " Top K precision = 0.09892473118279563, recall = 0.006873632574779217.\n",
            "Training on epoch 2 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693386, and regularization loss is 0.000238.\n",
            " Top K precision = 0.09484536082474224, recall = 0.00825001642840253.\n",
            "Training on epoch 2 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693389, and regularization loss is 0.000241.\n",
            " Top K precision = 0.09791666666666664, recall = 0.008968959184361754.\n",
            "Training on epoch 2 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693506, and regularization loss is 0.000358.\n",
            " Top K precision = 0.09285714285714282, recall = 0.008478593838542527.\n",
            "Training on epoch 2 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693505, and regularization loss is 0.000358.\n",
            " Top K precision = 0.08709677419354836, recall = 0.0061569453438497556.\n",
            "\n",
            "Training on 2 epoch completed.\n",
            " Average bpr_loss on train set is 0.005423 for the current epoch.\n",
            " Training top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 3 epoch\n",
            "Training on epoch 3 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693391, and regularization loss is 0.000243.\n",
            " Top K precision = 0.08369565217391303, recall = 0.007991101604793228.\n",
            "Training on epoch 3 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693443, and regularization loss is 0.000296.\n",
            " Top K precision = 0.08105263157894733, recall = 0.008199278282305388.\n",
            "Training on epoch 3 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693421, and regularization loss is 0.000274.\n",
            " Top K precision = 0.0989583333333333, recall = 0.007263615235562221.\n",
            "Training on epoch 3 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693271, and regularization loss is 0.000123.\n",
            " Top K precision = 0.08510638297872339, recall = 0.008251177238848061.\n",
            "Training on epoch 3 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693429, and regularization loss is 0.000282.\n",
            " Top K precision = 0.09787234042553188, recall = 0.0078119863087167925.\n",
            "Training on epoch 3 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693455, and regularization loss is 0.000308.\n",
            " Top K precision = 0.09462365591397846, recall = 0.008741299120457905.\n",
            "Training on epoch 3 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693379, and regularization loss is 0.000232.\n",
            " Top K precision = 0.09999999999999996, recall = 0.007705331748586254.\n",
            "Training on epoch 3 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693252, and regularization loss is 0.000105.\n",
            " Top K precision = 0.08571428571428566, recall = 0.007328731847080416.\n",
            "\n",
            "Training on 3 epoch completed.\n",
            " Average bpr_loss on train set is 0.005422 for the current epoch.\n",
            " Training top K precision = 0.08899999999999997, recall = 0.007558772127474775.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 4 epoch\n",
            "Training on epoch 4 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693259, and regularization loss is 0.000112.\n",
            " Top K precision = 0.096078431372549, recall = 0.007722740086867187.\n",
            "Training on epoch 4 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693225, and regularization loss is 7.8e-05.\n",
            " Top K precision = 0.08539325842696628, recall = 0.00820629704479299.\n",
            "Training on epoch 4 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693233, and regularization loss is 8.6e-05.\n",
            " Top K precision = 0.09899999999999995, recall = 0.009238303550664346.\n",
            "Training on epoch 4 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693185, and regularization loss is 3.8e-05.\n",
            " Top K precision = 0.07977528089887638, recall = 0.007349568887000372.\n",
            "Training on epoch 4 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693189, and regularization loss is 4.2e-05.\n",
            " Top K precision = 0.09897959183673463, recall = 0.0078185459565832.\n",
            "Training on epoch 4 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693283, and regularization loss is 0.000136.\n",
            " Top K precision = 0.08681318681318677, recall = 0.005863564402223081.\n",
            "Training on epoch 4 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693209, and regularization loss is 6.2e-05.\n",
            " Top K precision = 0.08494623655913978, recall = 0.0070495925604498345.\n",
            "Training on epoch 4 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693245, and regularization loss is 9.8e-05.\n",
            " Top K precision = 0.07979797979797977, recall = 0.006795591755587405.\n",
            "\n",
            "Training on 4 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.0889999999999999, recall = 0.007558772127474776.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 5 epoch\n",
            "Training on epoch 5 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.08842105263157891, recall = 0.007764175348619953.\n",
            "Training on epoch 5 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693192, and regularization loss is 4.5e-05.\n",
            " Top K precision = 0.0802197802197802, recall = 0.00724489579570638.\n",
            "Training on epoch 5 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693204, and regularization loss is 5.6e-05.\n",
            " Top K precision = 0.09899999999999992, recall = 0.008979928055259464.\n",
            "Training on epoch 5 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693235, and regularization loss is 8.8e-05.\n",
            " Top K precision = 0.08437499999999999, recall = 0.006746077717334328.\n",
            "Training on epoch 5 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693262, and regularization loss is 0.000115.\n",
            " Top K precision = 0.08333333333333333, recall = 0.006288859657755543.\n",
            "Training on epoch 5 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 8e-06.\n",
            " Top K precision = 0.08144329896907215, recall = 0.007015288118997099.\n",
            "Training on epoch 5 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693207, and regularization loss is 6e-05.\n",
            " Top K precision = 0.09999999999999992, recall = 0.009044416099816321.\n",
            "Training on epoch 5 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.09784946236559132, recall = 0.008204980504209022.\n",
            "\n",
            "Training on 5 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 6 epoch\n",
            "Training on epoch 6 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693154, and regularization loss is 7e-06.\n",
            " Top K precision = 0.10097087378640772, recall = 0.008974483975787078.\n",
            "Training on epoch 6 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693184, and regularization loss is 3.7e-05.\n",
            " Top K precision = 0.09222222222222219, recall = 0.007240322098231429.\n",
            "Training on epoch 6 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693154, and regularization loss is 6e-06.\n",
            " Top K precision = 0.09120879120879116, recall = 0.00676919192728771.\n",
            "Training on epoch 6 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09789473684210521, recall = 0.007758343672956285.\n",
            "Training on epoch 6 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09090909090909084, recall = 0.007872997408603801.\n",
            "Training on epoch 6 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.69318, and regularization loss is 3.2e-05.\n",
            " Top K precision = 0.0810526315789473, recall = 0.006090316841342232.\n",
            "Training on epoch 6 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693154, and regularization loss is 7e-06.\n",
            " Top K precision = 0.07551020408163266, recall = 0.006870076047279689.\n",
            "Training on epoch 6 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693178, and regularization loss is 3.1e-05.\n",
            " Top K precision = 0.0835164835164835, recall = 0.006099792648713985.\n",
            "\n",
            "Training on 6 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999997, recall = 0.007558772127474776.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 7 epoch\n",
            "Training on epoch 7 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693151, and regularization loss is 3e-06.\n",
            " Top K precision = 0.0933333333333333, recall = 0.00844900827016653.\n",
            "Training on epoch 7 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693188, and regularization loss is 4e-05.\n",
            " Top K precision = 0.10898876404494379, recall = 0.009223357398596425.\n",
            "Training on epoch 7 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.0811111111111111, recall = 0.007478712862348056.\n",
            "Training on epoch 7 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693152, and regularization loss is 4e-06.\n",
            " Top K precision = 0.09101123595505616, recall = 0.009500060753443808.\n",
            "Training on epoch 7 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
            " Top K precision = 0.10206185567010302, recall = 0.008258745686907187.\n",
            "Training on epoch 7 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693153, and regularization loss is 5e-06.\n",
            " Top K precision = 0.10918367346938772, recall = 0.009948821680095265.\n",
            "Training on epoch 7 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.09560439560439558, recall = 0.006959976448719081.\n",
            "Training on epoch 7 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693155, and regularization loss is 7e-06.\n",
            " Top K precision = 0.0835164835164835, recall = 0.00678921531835513.\n",
            "\n",
            "Training on 7 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999995, recall = 0.007558772127474776.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 8 epoch\n",
            "Training on epoch 8 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693155, and regularization loss is 7e-06.\n",
            " Top K precision = 0.08958333333333329, recall = 0.007630815346159246.\n",
            "Training on epoch 8 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.0861702127659574, recall = 0.007739679652323211.\n",
            "Training on epoch 8 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.09052631578947365, recall = 0.005882314327430338.\n",
            "Training on epoch 8 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08510638297872337, recall = 0.007870675705719234.\n",
            "Training on epoch 8 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.5e-05.\n",
            " Top K precision = 0.09540229885057466, recall = 0.008192504341178417.\n",
            "Training on epoch 8 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.0811111111111111, recall = 0.007113076134334448.\n",
            "Training on epoch 8 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
            " Top K precision = 0.09191919191919191, recall = 0.008683032578499485.\n",
            "Training on epoch 8 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.09148936170212761, recall = 0.00815338707353429.\n",
            "\n",
            "Training on 8 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08799999999999994, recall = 0.007456731311148245.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 9 epoch\n",
            "Training on epoch 9 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.0887640449438202, recall = 0.007181959093810962.\n",
            "Training on epoch 9 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08673469387755098, recall = 0.007341779011117136.\n",
            "Training on epoch 9 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.08191489361702126, recall = 0.00617534251676587.\n",
            "Training on epoch 9 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08315789473684206, recall = 0.0061682551903742685.\n",
            "Training on epoch 9 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08617021276595742, recall = 0.009176748599454986.\n",
            "Training on epoch 9 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
            " Top K precision = 0.08631578947368415, recall = 0.007461230175322854.\n",
            "Training on epoch 9 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09120879120879116, recall = 0.008027462046419123.\n",
            "Training on epoch 9 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09687499999999995, recall = 0.00782348936773391.\n",
            "\n",
            "Training on 9 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.0885, recall = 0.007546517225513994.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08849999999999997, recall = 0.00771584788395212.\n",
            "\n",
            "Training on the 10 epoch\n",
            "Training on epoch 10 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.08695652173913039, recall = 0.006308547707959683.\n",
            "Training on epoch 10 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693153, and regularization loss is 6e-06.\n",
            " Top K precision = 0.08556701030927832, recall = 0.008933816588019453.\n",
            "Training on epoch 10 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.07894736842105259, recall = 0.007504242571754887.\n",
            "Training on epoch 10 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08791208791208788, recall = 0.007150073009867099.\n",
            "Training on epoch 10 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.10113636363636362, recall = 0.008973332429511422.\n",
            "Training on epoch 10 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.10116279069767439, recall = 0.0077723041746257686.\n",
            "Training on epoch 10 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09062499999999996, recall = 0.00759154731579554.\n",
            "Training on epoch 10 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09456521739130429, recall = 0.008593754728203893.\n",
            "\n",
            "Training on 10 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08649999999999995, recall = 0.0073724278853444245.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08949999999999995, recall = 0.007575778930195866.\n",
            "\n",
            "Training on the 11 epoch\n",
            "Training on epoch 11 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.07499999999999996, recall = 0.005521688858051345.\n",
            "Training on epoch 11 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.0917525773195876, recall = 0.007633598352883872.\n",
            "Training on epoch 11 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.10543478260869563, recall = 0.010212430517040818.\n",
            "Training on epoch 11 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.07666666666666665, recall = 0.007579661913805087.\n",
            "Training on epoch 11 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09108910891089105, recall = 0.00820508696838252.\n",
            "Training on epoch 11 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
            " Top K precision = 0.08199999999999998, recall = 0.006979804956676416.\n",
            "Training on epoch 11 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693179, and regularization loss is 3.2e-05.\n",
            " Top K precision = 0.08229166666666664, recall = 0.008323832538270935.\n",
            "Training on epoch 11 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.08235294117647056, recall = 0.006715945077367179.\n",
            "\n",
            "Training on 11 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08849999999999994, recall = 0.0075486430758541275.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08149999999999993, recall = 0.00707036384675547.\n",
            "\n",
            "Training on the 12 epoch\n",
            "Training on epoch 12 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08888888888888884, recall = 0.007397108435229133.\n",
            "Training on epoch 12 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.09157894736842101, recall = 0.00870297147618531.\n",
            "Training on epoch 12 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.11276595744680847, recall = 0.008622997623585567.\n",
            "Training on epoch 12 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.08431372549019604, recall = 0.006371699599230056.\n",
            "Training on epoch 12 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09325842696629211, recall = 0.008372228047128389.\n",
            "Training on epoch 12 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
            " Top K precision = 0.0852631578947368, recall = 0.009336100792162771.\n",
            "Training on epoch 12 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.0739583333333333, recall = 0.007876329274166123.\n",
            "Training on epoch 12 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08383838383838382, recall = 0.007186358919134715.\n",
            "\n",
            "Training on 12 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999997, recall = 0.007558772127474777.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 13 epoch\n",
            "Training on epoch 13 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.09247311827956987, recall = 0.0072167204852508155.\n",
            "Training on epoch 13 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.11182795698924726, recall = 0.008911981736596615.\n",
            "Training on epoch 13 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09072164948453604, recall = 0.00800785889225195.\n",
            "Training on epoch 13 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.06122448979591833, recall = 0.004062719451668227.\n",
            "Training on epoch 13 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.07727272727272723, recall = 0.006938068861689175.\n",
            "Training on epoch 13 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.085, recall = 0.006661065706317035.\n",
            "Training on epoch 13 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09368421052631573, recall = 0.00811462398183086.\n",
            "Training on epoch 13 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.07551020408163261, recall = 0.006771034541702344.\n",
            "\n",
            "Training on 13 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08949999999999993, recall = 0.007589259932352824.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08149999999999993, recall = 0.007252741769114943.\n",
            "\n",
            "Training on the 14 epoch\n",
            "Training on epoch 14 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08383838383838381, recall = 0.007633458036036086.\n",
            "Training on epoch 14 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09009900990099003, recall = 0.008456973152135462.\n",
            "Training on epoch 14 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09670329670329665, recall = 0.009590725157827691.\n",
            "Training on epoch 14 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.08673469387755095, recall = 0.007730095218690525.\n",
            "Training on epoch 14 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.07717391304347826, recall = 0.005792710577390216.\n",
            "Training on epoch 14 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.08899999999999998, recall = 0.007261735782713553.\n",
            "Training on epoch 14 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09670329670329665, recall = 0.007957324890962321.\n",
            "Training on epoch 14 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.08260869565217387, recall = 0.006166193720946142.\n",
            "\n",
            "Training on 14 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08649999999999991, recall = 0.0074917879722317645.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08799999999999995, recall = 0.007713843279829103.\n",
            "\n",
            "Training on the 15 epoch\n",
            "Training on epoch 15 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.08437499999999996, recall = 0.006450305605944542.\n",
            "Training on epoch 15 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.08901098901098899, recall = 0.007685348310707309.\n",
            "Training on epoch 15 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09292929292929289, recall = 0.008009481292676032.\n",
            "Training on epoch 15 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.08712871287128712, recall = 0.007339228342607975.\n",
            "Training on epoch 15 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09010989010989008, recall = 0.007440870484620423.\n",
            "Training on epoch 15 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.09120879120879118, recall = 0.00603950874274955.\n",
            "Training on epoch 15 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08260869565217388, recall = 0.007688376734362319.\n",
            "Training on epoch 15 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09157894736842105, recall = 0.0071010019244174384.\n",
            "\n",
            "Training on 15 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999993, recall = 0.007558772127474776.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08299999999999993, recall = 0.007358281263836105.\n",
            "\n",
            "Training on the 16 epoch\n",
            "Training on epoch 16 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08367346938775508, recall = 0.007128297929173584.\n",
            "Training on epoch 16 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08181818181818182, recall = 0.007111365377241019.\n",
            "Training on epoch 16 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
            " Top K precision = 0.08571428571428569, recall = 0.008353708576476526.\n",
            "Training on epoch 16 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.10721649484536079, recall = 0.009092950220157237.\n",
            "Training on epoch 16 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09333333333333332, recall = 0.008668313425098802.\n",
            "Training on epoch 16 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.08631578947368418, recall = 0.00594702290106512.\n",
            "Training on epoch 16 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.10543478260869563, recall = 0.008285970390588667.\n",
            "Training on epoch 16 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.07849462365591398, recall = 0.007010420515760237.\n",
            "\n",
            "Training on 16 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08749999999999998, recall = 0.007478490014629639.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 17 epoch\n",
            "Training on epoch 17 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.10315789473684207, recall = 0.009203155485208428.\n",
            "Training on epoch 17 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.10824742268041232, recall = 0.009747412046264987.\n",
            "Training on epoch 17 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.07731958762886593, recall = 0.006254138402601556.\n",
            "Training on epoch 17 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.07340425531914893, recall = 0.008418436677895614.\n",
            "Training on epoch 17 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.08555555555555552, recall = 0.008197043469463114.\n",
            "Training on epoch 17 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.07291666666666663, recall = 0.007792168389135171.\n",
            "Training on epoch 17 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.07613636363636361, recall = 0.007297983752071682.\n",
            "Training on epoch 17 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693175, and regularization loss is 2.7e-05.\n",
            " Top K precision = 0.09473684210526312, recall = 0.007285241299301613.\n",
            "\n",
            "Training on 17 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08900000000000002, recall = 0.007558772127474781.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08949999999999995, recall = 0.007575778930195866.\n",
            "\n",
            "Training on the 18 epoch\n",
            "Training on epoch 18 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.09278350515463915, recall = 0.008048612615986848.\n",
            "Training on epoch 18 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.0852631578947368, recall = 0.007377808414640473.\n",
            "Training on epoch 18 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09239130434782607, recall = 0.008805919511185404.\n",
            "Training on epoch 18 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08191489361702126, recall = 0.007245086278492891.\n",
            "Training on epoch 18 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08924731182795698, recall = 0.007561267200319362.\n",
            "Training on epoch 18 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09175257731958758, recall = 0.006335280493065765.\n",
            "Training on epoch 18 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
            " Top K precision = 0.10752688172043003, recall = 0.00779252692853254.\n",
            "Training on epoch 18 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.07727272727272726, recall = 0.004783816350882926.\n",
            "\n",
            "Training on 18 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999998, recall = 0.0075587721274747765.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08549999999999994, recall = 0.007391912257306291.\n",
            "\n",
            "Training on the 19 epoch\n",
            "Training on epoch 19 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.10210526315789471, recall = 0.007021807684267581.\n",
            "Training on epoch 19 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.0934065934065934, recall = 0.007403792788552236.\n",
            "Training on epoch 19 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
            " Top K precision = 0.09999999999999998, recall = 0.0072082225548468.\n",
            "Training on epoch 19 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.098876404494382, recall = 0.008214947198710713.\n",
            "Training on epoch 19 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.08367346938775508, recall = 0.0074992647922453096.\n",
            "Training on epoch 19 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08478260869565213, recall = 0.007859840240987272.\n",
            "Training on epoch 19 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693176, and regularization loss is 2.8e-05.\n",
            " Top K precision = 0.08172043010752689, recall = 0.005611413377968213.\n",
            "Training on epoch 19 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.07628865979381441, recall = 0.007473938123952167.\n",
            "\n",
            "Training on 19 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.09000000000000002, recall = 0.007594252880303571.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08649999999999995, recall = 0.0073841751006473244.\n",
            "\n",
            "Training on the 20 epoch\n",
            "Training on epoch 20 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.10721649484536078, recall = 0.008613261792645552.\n",
            "Training on epoch 20 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09036144578313253, recall = 0.007532004154658983.\n",
            "Training on epoch 20 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.07799999999999999, recall = 0.006631736985661174.\n",
            "Training on epoch 20 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09489795918367344, recall = 0.007676243783435569.\n",
            "Training on epoch 20 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09599999999999997, recall = 0.00716461661425386.\n",
            "Training on epoch 20 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.07684210526315788, recall = 0.006925050828295206.\n",
            "Training on epoch 20 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.10425531914893613, recall = 0.009228462950434337.\n",
            "Training on epoch 20 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.07708333333333332, recall = 0.006401994140131653.\n",
            "\n",
            "Training on 20 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999998, recall = 0.0075587721274747765.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08849999999999997, recall = 0.007507751719311511.\n",
            "\n",
            "Training on the 21 epoch\n",
            "Training on epoch 21 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09354838709677414, recall = 0.009296621052547523.\n",
            "Training on epoch 21 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.10106382978723402, recall = 0.0062546748456718025.\n",
            "Training on epoch 21 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09897959183673467, recall = 0.008492686949038954.\n",
            "Training on epoch 21 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.06631578947368418, recall = 0.007242339095691803.\n",
            "Training on epoch 21 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.07916666666666665, recall = 0.008009696838594071.\n",
            "Training on epoch 21 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.1153061224489795, recall = 0.008801333930717201.\n",
            "Training on epoch 21 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.08541666666666663, recall = 0.007548005192453192.\n",
            "Training on epoch 21 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08383838383838382, recall = 0.006157805651779877.\n",
            "\n",
            "Training on 21 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08849999999999997, recall = 0.00746948641318906.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08849999999999997, recall = 0.00771584788395212.\n",
            "\n",
            "Training on the 22 epoch\n",
            "Training on epoch 22 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09670329670329665, recall = 0.006887280159515576.\n",
            "Training on epoch 22 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09387755102040812, recall = 0.008284712354436185.\n",
            "Training on epoch 22 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
            " Top K precision = 0.09354838709677417, recall = 0.009210311685969932.\n",
            "Training on epoch 22 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.1061855670103092, recall = 0.008772067870821892.\n",
            "Training on epoch 22 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.0901960784313725, recall = 0.00803193777130974.\n",
            "Training on epoch 22 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.0933333333333333, recall = 0.008460852843167669.\n",
            "Training on epoch 22 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.08058252427184462, recall = 0.007635460535314169.\n",
            "Training on epoch 22 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09574468085106382, recall = 0.007452309658594359.\n",
            "\n",
            "Training on 22 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08749999999999993, recall = 0.007679686438428841.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 23 epoch\n",
            "Training on epoch 23 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.08315789473684208, recall = 0.0074590707244180186.\n",
            "Training on epoch 23 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.0840425531914893, recall = 0.006347815094668163.\n",
            "Training on epoch 23 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08181818181818179, recall = 0.007260095531185239.\n",
            "Training on epoch 23 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.10978260869565215, recall = 0.008349172909245412.\n",
            "Training on epoch 23 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.1081395348837209, recall = 0.007922186372560794.\n",
            "Training on epoch 23 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09270833333333332, recall = 0.00802766496637077.\n",
            "Training on epoch 23 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.083, recall = 0.0063978910001624536.\n",
            "Training on epoch 23 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.08099999999999995, recall = 0.0074344069364893715.\n",
            "\n",
            "Training on 23 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08599999999999994, recall = 0.0074528313326653675.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 24 epoch\n",
            "Training on epoch 24 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.0958762886597938, recall = 0.008441024083054015.\n",
            "Training on epoch 24 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.09587628865979377, recall = 0.00902539325431844.\n",
            "Training on epoch 24 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.06236559139784945, recall = 0.005095310268351147.\n",
            "Training on epoch 24 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693177, and regularization loss is 3e-05.\n",
            " Top K precision = 0.07954545454545453, recall = 0.006608301643315032.\n",
            "Training on epoch 24 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.09591836734693872, recall = 0.006937168927936459.\n",
            "Training on epoch 24 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08437499999999998, recall = 0.008220571645844598.\n",
            "Training on epoch 24 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.09999999999999994, recall = 0.007197222492713141.\n",
            "Training on epoch 24 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09361702127659571, recall = 0.007932771546526479.\n",
            "\n",
            "Training on 24 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999997, recall = 0.007558772127474776.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08349999999999995, recall = 0.007201205507358761.\n",
            "\n",
            "Training on the 25 epoch\n",
            "Training on epoch 25 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.08979591836734693, recall = 0.007083880212253529.\n",
            "Training on epoch 25 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.090625, recall = 0.007303952338262038.\n",
            "Training on epoch 25 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
            " Top K precision = 0.09120879120879118, recall = 0.007441135493650091.\n",
            "Training on epoch 25 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.10833333333333327, recall = 0.007749244857338235.\n",
            "Training on epoch 25 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08834951456310672, recall = 0.008187375983640128.\n",
            "Training on epoch 25 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.07916666666666665, recall = 0.009014691600068259.\n",
            "Training on epoch 25 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.08673469387755098, recall = 0.00740195522184863.\n",
            "Training on epoch 25 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.07575757575757572, recall = 0.006979973715451245.\n",
            "\n",
            "Training on 25 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999993, recall = 0.007558772127474775.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 26 epoch\n",
            "Training on epoch 26 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09775280898876401, recall = 0.008697089461845397.\n",
            "Training on epoch 26 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08617021276595742, recall = 0.007086068210981935.\n",
            "Training on epoch 26 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.09417475728155333, recall = 0.00899682192671068.\n",
            "Training on epoch 26 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.09354838709677417, recall = 0.00802938654616408.\n",
            "Training on epoch 26 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.69318, and regularization loss is 3.2e-05.\n",
            " Top K precision = 0.0828282828282828, recall = 0.006263590542740222.\n",
            "Training on epoch 26 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08510638297872339, recall = 0.007155843371693693.\n",
            "Training on epoch 26 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.0815533980582524, recall = 0.005339467546391018.\n",
            "Training on epoch 26 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.08977272727272725, recall = 0.007019037696453388.\n",
            "\n",
            "Training on 26 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999993, recall = 0.0075320235639717015.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08949999999999995, recall = 0.007575778930195866.\n",
            "\n",
            "Training on the 27 epoch\n",
            "Training on epoch 27 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.10340909090909088, recall = 0.008531100528550752.\n",
            "Training on epoch 27 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
            " Top K precision = 0.09148936170212764, recall = 0.006807680060883517.\n",
            "Training on epoch 27 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08494623655913976, recall = 0.00888716086152909.\n",
            "Training on epoch 27 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08297872340425531, recall = 0.007560404498467122.\n",
            "Training on epoch 27 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.09587628865979377, recall = 0.00879039402552316.\n",
            "Training on epoch 27 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.08020833333333331, recall = 0.008883348477319928.\n",
            "Training on epoch 27 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693177, and regularization loss is 3e-05.\n",
            " Top K precision = 0.08888888888888884, recall = 0.007168765379439177.\n",
            "Training on epoch 27 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.09120879120879118, recall = 0.008900932838238644.\n",
            "\n",
            "Training on 27 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08799999999999994, recall = 0.007463030126970871.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 28 epoch\n",
            "Training on epoch 28 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.08437499999999998, recall = 0.0068936891688614645.\n",
            "Training on epoch 28 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08817204301075264, recall = 0.007368338896108303.\n",
            "Training on epoch 28 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.10106382978723401, recall = 0.00622165900546359.\n",
            "Training on epoch 28 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09270833333333332, recall = 0.0071018665326835215.\n",
            "Training on epoch 28 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
            " Top K precision = 0.10299999999999995, recall = 0.008789123848181953.\n",
            "Training on epoch 28 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09285714285714282, recall = 0.00788834911698813.\n",
            "Training on epoch 28 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.09270833333333328, recall = 0.008848303138400673.\n",
            "Training on epoch 28 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09263157894736838, recall = 0.00834638010030202.\n",
            "\n",
            "Training on 28 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08949999999999994, recall = 0.0076531117501162805.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 29 epoch\n",
            "Training on epoch 29 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.0949494949494949, recall = 0.008750354084206437.\n",
            "Training on epoch 29 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09239130434782607, recall = 0.007479197098527799.\n",
            "Training on epoch 29 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.08617021276595739, recall = 0.009727340477668349.\n",
            "Training on epoch 29 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.07959183673469386, recall = 0.006608611230095428.\n",
            "Training on epoch 29 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09062499999999996, recall = 0.007867244543407646.\n",
            "Training on epoch 29 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.08484848484848484, recall = 0.0071111187039356516.\n",
            "Training on epoch 29 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09888888888888887, recall = 0.006767893629457892.\n",
            "Training on epoch 29 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.07326732673267325, recall = 0.006786498036193129.\n",
            "\n",
            "Training on 29 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999998, recall = 0.007558772127474773.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0077328546866732096.\n",
            "\n",
            "Training on the 30 epoch\n",
            "Training on epoch 30 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.08842105263157891, recall = 0.0071062764568849525.\n",
            "Training on epoch 30 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.09680851063829783, recall = 0.009444302776966746.\n",
            "Training on epoch 30 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.0858695652173913, recall = 0.006183350053484015.\n",
            "Training on epoch 30 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.10322580645161288, recall = 0.008529481643767382.\n",
            "Training on epoch 30 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09499999999999993, recall = 0.008960323449926725.\n",
            "Training on epoch 30 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.07999999999999997, recall = 0.0075390291994099174.\n",
            "Training on epoch 30 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.0927083333333333, recall = 0.006852987635897343.\n",
            "Training on epoch 30 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.0833333333333333, recall = 0.007257011860840369.\n",
            "\n",
            "Training on 30 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08900000000000001, recall = 0.007558772127474776.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 31 epoch\n",
            "Training on epoch 31 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.5e-05.\n",
            " Top K precision = 0.09560439560439556, recall = 0.007572363398223831.\n",
            "Training on epoch 31 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.09183673469387753, recall = 0.009062108877140027.\n",
            "Training on epoch 31 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.6e-05.\n",
            " Top K precision = 0.08510638297872336, recall = 0.007420632459151984.\n",
            "Training on epoch 31 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08350515463917524, recall = 0.008296303617743002.\n",
            "Training on epoch 31 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 9e-06.\n",
            " Top K precision = 0.0959183673469387, recall = 0.00849587979622178.\n",
            "Training on epoch 31 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08977272727272723, recall = 0.009011044083779314.\n",
            "Training on epoch 31 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09999999999999994, recall = 0.007539726334302804.\n",
            "Training on epoch 31 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08152173913043478, recall = 0.007298052538000837.\n",
            "\n",
            "Training on 31 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08849999999999998, recall = 0.0075247585220326.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 32 epoch\n",
            "Training on epoch 32 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.0824742268041237, recall = 0.0067625547087357876.\n",
            "Training on epoch 32 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09263157894736837, recall = 0.006491724791200296.\n",
            "Training on epoch 32 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.10113636363636366, recall = 0.00749175583247082.\n",
            "Training on epoch 32 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.0783505154639175, recall = 0.007875362949570527.\n",
            "Training on epoch 32 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08163265306122448, recall = 0.006342560339427668.\n",
            "Training on epoch 32 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.6e-05.\n",
            " Top K precision = 0.08260869565217388, recall = 0.008212288560257684.\n",
            "Training on epoch 32 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.07142857142857142, recall = 0.007817336194313596.\n",
            "Training on epoch 32 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09999999999999998, recall = 0.008938860741949196.\n",
            "\n",
            "Training on 32 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999993, recall = 0.007633480582285274.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.07999999999999993, recall = 0.0070343456371902745.\n",
            "\n",
            "Training on the 33 epoch\n",
            "Training on epoch 33 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09072164948453605, recall = 0.006618085410302145.\n",
            "Training on epoch 33 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08787878787878782, recall = 0.007482207050181769.\n",
            "Training on epoch 33 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.09890109890109887, recall = 0.008750161828499676.\n",
            "Training on epoch 33 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.10322580645161286, recall = 0.006678192756493147.\n",
            "Training on epoch 33 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09292929292929289, recall = 0.006583226373583443.\n",
            "Training on epoch 33 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.0944444444444444, recall = 0.007443865516160197.\n",
            "Training on epoch 33 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.07684210526315782, recall = 0.006883424675551841.\n",
            "Training on epoch 33 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.08526315789473682, recall = 0.007862760347393737.\n",
            "\n",
            "Training on 33 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.0885, recall = 0.007524758522032599.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08849999999999997, recall = 0.007507751719311511.\n",
            "\n",
            "Training on the 34 epoch\n",
            "Training on epoch 34 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08958333333333329, recall = 0.006059602025674352.\n",
            "Training on epoch 34 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693177, and regularization loss is 3e-05.\n",
            " Top K precision = 0.09587628865979377, recall = 0.008946221569248056.\n",
            "Training on epoch 34 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.09239130434782605, recall = 0.005991791491467125.\n",
            "Training on epoch 34 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.08490566037735849, recall = 0.0072759367269727825.\n",
            "Training on epoch 34 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09333333333333328, recall = 0.00742131215992979.\n",
            "Training on epoch 34 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.08369565217391303, recall = 0.006905160663598596.\n",
            "Training on epoch 34 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.09690721649484524, recall = 0.007127024482548144.\n",
            "Training on epoch 34 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08817204301075264, recall = 0.008529184685407433.\n",
            "\n",
            "Training on 34 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08799999999999994, recall = 0.00751031364151629.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08349999999999995, recall = 0.007201205507358761.\n",
            "\n",
            "Training on the 35 epoch\n",
            "Training on epoch 35 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09687499999999998, recall = 0.008748090052939275.\n",
            "Training on epoch 35 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.0845360824742268, recall = 0.0072868524879347125.\n",
            "Training on epoch 35 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.09784946236559133, recall = 0.008553570263401448.\n",
            "Training on epoch 35 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693179, and regularization loss is 3.2e-05.\n",
            " Top K precision = 0.0824175824175824, recall = 0.009634943876509346.\n",
            "Training on epoch 35 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.08799999999999997, recall = 0.007701074030963122.\n",
            "Training on epoch 35 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.4e-05.\n",
            " Top K precision = 0.1010204081632653, recall = 0.007830056068880266.\n",
            "Training on epoch 35 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.08297872340425531, recall = 0.006824011441423329.\n",
            "Training on epoch 35 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.08510638297872339, recall = 0.007297800972719172.\n",
            "\n",
            "Training on 35 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08849999999999997, recall = 0.007524049905252557.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08949999999999995, recall = 0.007575778930195866.\n",
            "\n",
            "Training on the 36 epoch\n",
            "Training on epoch 36 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693176, and regularization loss is 2.9e-05.\n",
            " Top K precision = 0.07934782608695648, recall = 0.006914008365134144.\n",
            "Training on epoch 36 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.7e-05.\n",
            " Top K precision = 0.07319587628865978, recall = 0.007776960046073894.\n",
            "Training on epoch 36 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09130434782608696, recall = 0.008187801749732791.\n",
            "Training on epoch 36 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.08899999999999998, recall = 0.008071564092563543.\n",
            "Training on epoch 36 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.06333333333333331, recall = 0.005788832778224504.\n",
            "Training on epoch 36 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.06702127659574464, recall = 0.007324994195993846.\n",
            "Training on epoch 36 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08817204301075267, recall = 0.008243100549036556.\n",
            "Training on epoch 36 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.08924731182795698, recall = 0.006318793944389465.\n",
            "\n",
            "Training on 36 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08849999999999994, recall = 0.0075441948679995565.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08799999999999995, recall = 0.00753976072063067.\n",
            "\n",
            "Training on the 37 epoch\n",
            "Training on epoch 37 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.07865168539325841, recall = 0.006784225711992733.\n",
            "Training on epoch 37 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693175, and regularization loss is 2.8e-05.\n",
            " Top K precision = 0.09901960784313724, recall = 0.007899762306513007.\n",
            "Training on epoch 37 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09777777777777777, recall = 0.00745529442451531.\n",
            "Training on epoch 37 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.10439560439560436, recall = 0.006777903832337925.\n",
            "Training on epoch 37 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
            " Top K precision = 0.09893617021276593, recall = 0.00812447243959491.\n",
            "Training on epoch 37 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09550561797752807, recall = 0.008462742336127926.\n",
            "Training on epoch 37 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08854166666666663, recall = 0.007107096047249799.\n",
            "Training on epoch 37 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.08602150537634405, recall = 0.008264194290974844.\n",
            "\n",
            "Training on 37 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.0895, recall = 0.007565501602575719.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08849999999999997, recall = 0.00771584788395212.\n",
            "\n",
            "Training on the 38 epoch\n",
            "Training on epoch 38 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.09662921348314603, recall = 0.009492595383907692.\n",
            "Training on epoch 38 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08571428571428567, recall = 0.009511269672036944.\n",
            "Training on epoch 38 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.09569892473118276, recall = 0.008692006764115214.\n",
            "Training on epoch 38 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08444444444444443, recall = 0.00818053305350951.\n",
            "Training on epoch 38 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.08023255813953487, recall = 0.0058711972079467595.\n",
            "Training on epoch 38 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09684210526315787, recall = 0.008455772759866668.\n",
            "Training on epoch 38 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
            " Top K precision = 0.09484536082474222, recall = 0.009431338361541789.\n",
            "Training on epoch 38 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09797979797979796, recall = 0.007582693559744768.\n",
            "\n",
            "Training on 38 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999998, recall = 0.007539639474413552.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08849999999999997, recall = 0.00771584788395212.\n",
            "\n",
            "Training on the 39 epoch\n",
            "Training on epoch 39 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.08556701030927832, recall = 0.007469973482273732.\n",
            "Training on epoch 39 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.0887640449438202, recall = 0.00859712134907393.\n",
            "Training on epoch 39 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.08349514563106793, recall = 0.006661728418324397.\n",
            "Training on epoch 39 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.07956989247311826, recall = 0.007430922019490372.\n",
            "Training on epoch 39 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
            " Top K precision = 0.09999999999999994, recall = 0.008056782466990613.\n",
            "Training on epoch 39 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08235294117647059, recall = 0.007362331624234484.\n",
            "Training on epoch 39 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.10288461538461531, recall = 0.008771518171322289.\n",
            "Training on epoch 39 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08095238095238097, recall = 0.006836022255163986.\n",
            "\n",
            "Training on 39 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999993, recall = 0.007558772127474775.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08949999999999995, recall = 0.007575778930195866.\n",
            "\n",
            "Training on the 40 epoch\n",
            "Training on epoch 40 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693175, and regularization loss is 2.8e-05.\n",
            " Top K precision = 0.08350515463917525, recall = 0.006678965003900746.\n",
            "Training on epoch 40 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09029126213592227, recall = 0.008136858538112426.\n",
            "Training on epoch 40 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08901098901098897, recall = 0.008026071758762639.\n",
            "Training on epoch 40 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.08854166666666664, recall = 0.007852626288165172.\n",
            "Training on epoch 40 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08762886597938138, recall = 0.007310977745061895.\n",
            "Training on epoch 40 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.07938144329896901, recall = 0.007092706233305494.\n",
            "Training on epoch 40 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.08365384615384613, recall = 0.006890236244808949.\n",
            "Training on epoch 40 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09263157894736841, recall = 0.007923067905634277.\n",
            "\n",
            "Training on 40 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999998, recall = 0.007558772127474779.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 41 epoch\n",
            "Training on epoch 41 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.06881720430107527, recall = 0.006628447571958331.\n",
            "Training on epoch 41 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09108910891089105, recall = 0.008110932458450914.\n",
            "Training on epoch 41 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08913043478260865, recall = 0.008582116150283743.\n",
            "Training on epoch 41 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.0791208791208791, recall = 0.006342248068788191.\n",
            "Training on epoch 41 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.0727272727272727, recall = 0.005640778758473759.\n",
            "Training on epoch 41 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.09310344827586206, recall = 0.007732287870309305.\n",
            "Training on epoch 41 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.09677419354838705, recall = 0.006580996193498018.\n",
            "Training on epoch 41 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08627450980392151, recall = 0.006741325671636701.\n",
            "\n",
            "Training on 41 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08799999999999994, recall = 0.007443829598739144.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08399999999999994, recall = 0.007504687035393225.\n",
            "\n",
            "Training on the 42 epoch\n",
            "Training on epoch 42 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.5e-05.\n",
            " Top K precision = 0.08282828282828282, recall = 0.008136816534681152.\n",
            "Training on epoch 42 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.10312499999999998, recall = 0.00827443974254845.\n",
            "Training on epoch 42 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.11222222222222215, recall = 0.007820136991714554.\n",
            "Training on epoch 42 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09285714285714287, recall = 0.007196318970793527.\n",
            "Training on epoch 42 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.10105263157894731, recall = 0.007567388148618895.\n",
            "Training on epoch 42 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.09278350515463914, recall = 0.007034255833740245.\n",
            "Training on epoch 42 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08804347826086954, recall = 0.006847126470586547.\n",
            "Training on epoch 42 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09456521739130432, recall = 0.006878222793962946.\n",
            "\n",
            "Training on 42 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08849999999999993, recall = 0.007532285726462758.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08849999999999997, recall = 0.00771584788395212.\n",
            "\n",
            "Training on the 43 epoch\n",
            "Training on epoch 43 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.07835051546391748, recall = 0.005698227903967996.\n",
            "Training on epoch 43 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.07978723404255317, recall = 0.00755403757595648.\n",
            "Training on epoch 43 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.0864583333333333, recall = 0.006970624099165121.\n",
            "Training on epoch 43 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09569892473118276, recall = 0.00749667373045851.\n",
            "Training on epoch 43 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08659793814432988, recall = 0.007641930862286172.\n",
            "Training on epoch 43 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09468085106382977, recall = 0.006569166886606343.\n",
            "Training on epoch 43 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.09042553191489357, recall = 0.007920563316228254.\n",
            "Training on epoch 43 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08932038834951454, recall = 0.006770998304665395.\n",
            "\n",
            "Training on 43 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08799999999999997, recall = 0.007515252818610548.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08649999999999995, recall = 0.007410923664150398.\n",
            "\n",
            "Training on the 44 epoch\n",
            "Training on epoch 44 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.10699999999999994, recall = 0.008667490507491982.\n",
            "Training on epoch 44 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08901098901098901, recall = 0.007989046374797837.\n",
            "Training on epoch 44 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09191919191919189, recall = 0.008971170219592728.\n",
            "Training on epoch 44 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.07659574468085102, recall = 0.007484673253560278.\n",
            "Training on epoch 44 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08709677419354839, recall = 0.006580203227728629.\n",
            "Training on epoch 44 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.10227272727272724, recall = 0.007520348532305138.\n",
            "Training on epoch 44 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.09166666666666666, recall = 0.00645990296655054.\n",
            "Training on epoch 44 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.08854166666666667, recall = 0.007266089241419554.\n",
            "\n",
            "Training on 44 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08849999999999998, recall = 0.00754419486799956.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0077328546866732096.\n",
            "\n",
            "Training on the 45 epoch\n",
            "Training on epoch 45 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08977272727272727, recall = 0.006602308719513281.\n",
            "Training on epoch 45 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09484536082474224, recall = 0.007310947936924005.\n",
            "Training on epoch 45 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.0797872340425532, recall = 0.0059988831430912715.\n",
            "Training on epoch 45 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09320388349514559, recall = 0.007440021889765359.\n",
            "Training on epoch 45 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08437499999999996, recall = 0.007656221406935552.\n",
            "Training on epoch 45 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.06421052631578945, recall = 0.006070579742075442.\n",
            "Training on epoch 45 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.6e-05.\n",
            " Top K precision = 0.08585858585858586, recall = 0.007887422567070201.\n",
            "Training on epoch 45 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09130434782608696, recall = 0.007049037950144705.\n",
            "\n",
            "Training on 45 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.0885, recall = 0.007524758522032599.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 46 epoch\n",
            "Training on epoch 46 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.0884615384615384, recall = 0.00732618901952523.\n",
            "Training on epoch 46 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.08279569892473118, recall = 0.0068528603932964645.\n",
            "Training on epoch 46 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
            " Top K precision = 0.078021978021978, recall = 0.0063692810356999465.\n",
            "Training on epoch 46 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.07934782608695652, recall = 0.007171248268163964.\n",
            "Training on epoch 46 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.0864583333333333, recall = 0.006116377295707917.\n",
            "Training on epoch 46 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.09148936170212764, recall = 0.006749770136459502.\n",
            "Training on epoch 46 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693176, and regularization loss is 2.9e-05.\n",
            " Top K precision = 0.08936170212765954, recall = 0.008523568614837248.\n",
            "Training on epoch 46 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08791208791208789, recall = 0.007248051331653932.\n",
            "\n",
            "Training on 46 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999998, recall = 0.0075587721274747765.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.007553457501624437.\n",
            "\n",
            "Training on the 47 epoch\n",
            "Training on epoch 47 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08659793814432987, recall = 0.009163840614593008.\n",
            "Training on epoch 47 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
            " Top K precision = 0.08936170212765956, recall = 0.008632196405157586.\n",
            "Training on epoch 47 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09186046511627906, recall = 0.008736053438595744.\n",
            "Training on epoch 47 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08791208791208788, recall = 0.007217451078179621.\n",
            "Training on epoch 47 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.09677419354838705, recall = 0.008095233412669765.\n",
            "Training on epoch 47 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08421052631578946, recall = 0.008719905193309991.\n",
            "Training on epoch 47 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
            " Top K precision = 0.0936170212765957, recall = 0.008320638756298484.\n",
            "Training on epoch 47 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
            " Top K precision = 0.07555555555555556, recall = 0.00831408211955239.\n",
            "\n",
            "Training on 47 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08749999999999997, recall = 0.007500675559135328.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08799999999999995, recall = 0.00753976072063067.\n",
            "\n",
            "Training on the 48 epoch\n",
            "Training on epoch 48 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09897959183673469, recall = 0.006609812272561059.\n",
            "Training on epoch 48 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.09450549450549449, recall = 0.008106915223954321.\n",
            "Training on epoch 48 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09999999999999995, recall = 0.008611452941881289.\n",
            "Training on epoch 48 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09130434782608692, recall = 0.008832500902334645.\n",
            "Training on epoch 48 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693177, and regularization loss is 3e-05.\n",
            " Top K precision = 0.07578947368421048, recall = 0.0074301101903564495.\n",
            "Training on epoch 48 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.08709677419354835, recall = 0.006925269898306894.\n",
            "Training on epoch 48 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08275862068965516, recall = 0.007451317370211127.\n",
            "Training on epoch 48 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.08969072164948451, recall = 0.007465549123057414.\n",
            "\n",
            "Training on 48 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999998, recall = 0.007558772127474777.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 49 epoch\n",
            "Training on epoch 49 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693177, and regularization loss is 3e-05.\n",
            " Top K precision = 0.06888888888888886, recall = 0.007609331911229917.\n",
            "Training on epoch 49 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.6e-05.\n",
            " Top K precision = 0.09583333333333327, recall = 0.006764081150281188.\n",
            "Training on epoch 49 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.08541666666666668, recall = 0.0067406051907084.\n",
            "Training on epoch 49 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.07741935483870967, recall = 0.0075327718420672846.\n",
            "Training on epoch 49 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.07653061224489793, recall = 0.0071841741013989316.\n",
            "Training on epoch 49 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08673469387755098, recall = 0.008548272786022399.\n",
            "Training on epoch 49 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.0833333333333333, recall = 0.006746166318343437.\n",
            "Training on epoch 49 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.08817204301075268, recall = 0.007075019133184821.\n",
            "\n",
            "Training on 49 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999993, recall = 0.007558772127474776.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 50 epoch\n",
            "Training on epoch 50 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.0840425531914893, recall = 0.00859860556396698.\n",
            "Training on epoch 50 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08846153846153842, recall = 0.008762751751993004.\n",
            "Training on epoch 50 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.08279569892473114, recall = 0.006339036651343164.\n",
            "Training on epoch 50 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08124999999999995, recall = 0.007025806614815228.\n",
            "Training on epoch 50 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.10618556701030925, recall = 0.008203129797378823.\n",
            "Training on epoch 50 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08749999999999998, recall = 0.0074914671816190895.\n",
            "Training on epoch 50 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.09793814432989686, recall = 0.006301228690328214.\n",
            "Training on epoch 50 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693175, and regularization loss is 2.7e-05.\n",
            " Top K precision = 0.0904255319148936, recall = 0.008693219473199516.\n",
            "\n",
            "Training on 50 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08799999999999994, recall = 0.007501394036051291.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08399999999999994, recall = 0.00721821231007985.\n",
            "\n",
            "Training on the 51 epoch\n",
            "Training on epoch 51 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.6e-05.\n",
            " Top K precision = 0.0904255319148936, recall = 0.0059662310793483.\n",
            "Training on epoch 51 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09489795918367344, recall = 0.007100224606506615.\n",
            "Training on epoch 51 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.0855670103092783, recall = 0.00759948470859732.\n",
            "Training on epoch 51 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.07899999999999995, recall = 0.008223880822791447.\n",
            "Training on epoch 51 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.09381443298969068, recall = 0.007074461282516161.\n",
            "Training on epoch 51 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08947368421052627, recall = 0.00800065041303535.\n",
            "Training on epoch 51 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.09381443298969068, recall = 0.008218033368114984.\n",
            "Training on epoch 51 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.0969072164948453, recall = 0.008136449130929686.\n",
            "\n",
            "Training on 51 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999995, recall = 0.00755877212747478.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08849999999999997, recall = 0.00771584788395212.\n",
            "\n",
            "Training on the 52 epoch\n",
            "Training on epoch 52 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09278350515463912, recall = 0.007144031887731943.\n",
            "Training on epoch 52 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693177, and regularization loss is 3e-05.\n",
            " Top K precision = 0.08437499999999998, recall = 0.0075000346598855586.\n",
            "Training on epoch 52 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09374999999999996, recall = 0.006731176798715636.\n",
            "Training on epoch 52 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.0927083333333333, recall = 0.006906782793828705.\n",
            "Training on epoch 52 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.07311827956989245, recall = 0.006507003251692165.\n",
            "Training on epoch 52 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.0742268041237113, recall = 0.007192969163936411.\n",
            "Training on epoch 52 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08749999999999995, recall = 0.0074980806587351895.\n",
            "Training on epoch 52 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.087, recall = 0.00735765675134653.\n",
            "\n",
            "Training on 52 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.088, recall = 0.007456731311148248.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08749999999999995, recall = 0.007696836477108015.\n",
            "\n",
            "Training on the 53 epoch\n",
            "Training on epoch 53 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.4e-05.\n",
            " Top K precision = 0.08350515463917525, recall = 0.007490530192366831.\n",
            "Training on epoch 53 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.07731958762886597, recall = 0.006131890397339822.\n",
            "Training on epoch 53 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09010989010989011, recall = 0.008179185714877798.\n",
            "Training on epoch 53 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693178, and regularization loss is 3.1e-05.\n",
            " Top K precision = 0.08510638297872339, recall = 0.007752323529805338.\n",
            "Training on epoch 53 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.7e-05.\n",
            " Top K precision = 0.09687499999999999, recall = 0.007996445988049756.\n",
            "Training on epoch 53 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08333333333333333, recall = 0.008492149820907029.\n",
            "Training on epoch 53 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
            " Top K precision = 0.08901098901098899, recall = 0.007103771349322521.\n",
            "Training on epoch 53 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.09578947368421052, recall = 0.0070676367963522025.\n",
            "\n",
            "Training on 53 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999993, recall = 0.007558772127474773.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 54 epoch\n",
            "Training on epoch 54 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 9e-06.\n",
            " Top K precision = 0.08979591836734693, recall = 0.007907878461574081.\n",
            "Training on epoch 54 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.09479166666666662, recall = 0.007108433740452.\n",
            "Training on epoch 54 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693176, and regularization loss is 2.8e-05.\n",
            " Top K precision = 0.0958762886597938, recall = 0.008074600243981047.\n",
            "Training on epoch 54 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.09680851063829782, recall = 0.009069217843226087.\n",
            "Training on epoch 54 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08499999999999998, recall = 0.007810529056143177.\n",
            "Training on epoch 54 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09230769230769226, recall = 0.007501917325120409.\n",
            "Training on epoch 54 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08989898989898987, recall = 0.0069587012221951775.\n",
            "Training on epoch 54 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.09479166666666665, recall = 0.007872320986714124.\n",
            "\n",
            "Training on 54 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08649999999999998, recall = 0.007407232099426089.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08349999999999995, recall = 0.007201205507358761.\n",
            "\n",
            "Training on the 55 epoch\n",
            "Training on epoch 55 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.10329670329670322, recall = 0.008738329500547976.\n",
            "Training on epoch 55 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.11145833333333327, recall = 0.0073181208638560084.\n",
            "Training on epoch 55 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08999999999999996, recall = 0.005559954459199545.\n",
            "Training on epoch 55 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.09325842696629211, recall = 0.007899104384916754.\n",
            "Training on epoch 55 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.09484536082474224, recall = 0.007873608941650054.\n",
            "Training on epoch 55 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.09892473118279566, recall = 0.0096073276992058.\n",
            "Training on epoch 55 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09157894736842102, recall = 0.007069777805822032.\n",
            "Training on epoch 55 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
            " Top K precision = 0.09456521739130432, recall = 0.00920830992127651.\n",
            "\n",
            "Training on 55 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999993, recall = 0.00755877212747478.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.07999999999999993, recall = 0.007059489103244309.\n",
            "\n",
            "Training on the 56 epoch\n",
            "Training on epoch 56 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.09555555555555555, recall = 0.008813853235128014.\n",
            "Training on epoch 56 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.4e-05.\n",
            " Top K precision = 0.08556701030927832, recall = 0.008451476368039158.\n",
            "Training on epoch 56 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.6e-05.\n",
            " Top K precision = 0.08913043478260867, recall = 0.00809888534927226.\n",
            "Training on epoch 56 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.08777777777777776, recall = 0.00803747988792671.\n",
            "Training on epoch 56 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08476190476190472, recall = 0.008631511926921936.\n",
            "Training on epoch 56 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.08842105263157893, recall = 0.006499415046644388.\n",
            "Training on epoch 56 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
            " Top K precision = 0.09009900990099005, recall = 0.007835329692010841.\n",
            "Training on epoch 56 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.09799999999999993, recall = 0.008357522821803258.\n",
            "\n",
            "Training on 56 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08849999999999991, recall = 0.007543891175093823.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08199999999999993, recall = 0.007339269856991999.\n",
            "\n",
            "Training on the 57 epoch\n",
            "Training on epoch 57 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.07666666666666667, recall = 0.006827030285116513.\n",
            "Training on epoch 57 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08936170212765954, recall = 0.008469534430524438.\n",
            "Training on epoch 57 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09595959595959591, recall = 0.00842835572817914.\n",
            "Training on epoch 57 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.08421052631578944, recall = 0.006322521110871727.\n",
            "Training on epoch 57 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08695652173913042, recall = 0.00645194874379857.\n",
            "Training on epoch 57 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09032258064516127, recall = 0.008075498733031898.\n",
            "Training on epoch 57 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08404255319148936, recall = 0.007160058634030019.\n",
            "Training on epoch 57 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.08510638297872336, recall = 0.008008241213062522.\n",
            "\n",
            "Training on 57 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08749999999999997, recall = 0.007576433924317756.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08549999999999994, recall = 0.007391912257306291.\n",
            "\n",
            "Training on the 58 epoch\n",
            "Training on epoch 58 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.07999999999999997, recall = 0.006173621529285426.\n",
            "Training on epoch 58 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09574468085106379, recall = 0.006338802398167795.\n",
            "Training on epoch 58 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09062499999999997, recall = 0.007540504545969727.\n",
            "Training on epoch 58 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08316831683168313, recall = 0.0062603495209397975.\n",
            "Training on epoch 58 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.08297872340425526, recall = 0.007434423792349653.\n",
            "Training on epoch 58 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.10210526315789469, recall = 0.007495629212206963.\n",
            "Training on epoch 58 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.08617021276595742, recall = 0.007364686029212711.\n",
            "Training on epoch 58 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08659793814432987, recall = 0.007194001270562201.\n",
            "\n",
            "Training on 58 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08900000000000001, recall = 0.007558772127474776.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 59 epoch\n",
            "Training on epoch 59 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.0824175824175824, recall = 0.007262199230327041.\n",
            "Training on epoch 59 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.08817204301075268, recall = 0.007658419919382558.\n",
            "Training on epoch 59 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
            " Top K precision = 0.09499999999999996, recall = 0.007788968066365662.\n",
            "Training on epoch 59 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.0913978494623656, recall = 0.008871740047683305.\n",
            "Training on epoch 59 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.07938144329896905, recall = 0.005036459388836383.\n",
            "Training on epoch 59 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.08977272727272727, recall = 0.006545031037880708.\n",
            "Training on epoch 59 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09148936170212764, recall = 0.007915543491290828.\n",
            "Training on epoch 59 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08602150537634408, recall = 0.006336714035373602.\n",
            "\n",
            "Training on 59 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08949999999999995, recall = 0.007604643687107805.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 60 epoch\n",
            "Training on epoch 60 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
            " Top K precision = 0.08105263157894732, recall = 0.008969284464313875.\n",
            "Training on epoch 60 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 8e-06.\n",
            " Top K precision = 0.0934065934065934, recall = 0.008613589754677055.\n",
            "Training on epoch 60 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09019607843137255, recall = 0.00640805787479472.\n",
            "Training on epoch 60 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09052631578947365, recall = 0.008900899335264653.\n",
            "Training on epoch 60 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.10315789473684207, recall = 0.008027052332510014.\n",
            "Training on epoch 60 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
            " Top K precision = 0.09072164948453605, recall = 0.008027095906324775.\n",
            "Training on epoch 60 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.08556701030927828, recall = 0.007245090839013336.\n",
            "Training on epoch 60 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.0802083333333333, recall = 0.007520981431486675.\n",
            "\n",
            "Training on 60 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999995, recall = 0.007558772127474776.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08649999999999995, recall = 0.007410923664150398.\n",
            "\n",
            "Training on the 61 epoch\n",
            "Training on epoch 61 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08235294117647057, recall = 0.008376814829610576.\n",
            "Training on epoch 61 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.11999999999999998, recall = 0.009807215949376873.\n",
            "Training on epoch 61 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
            " Top K precision = 0.09186046511627904, recall = 0.007205975144547487.\n",
            "Training on epoch 61 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.07888888888888884, recall = 0.006298474280609251.\n",
            "Training on epoch 61 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.10105263157894731, recall = 0.009571870793662778.\n",
            "Training on epoch 61 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.08602150537634405, recall = 0.009124776887661237.\n",
            "Training on epoch 61 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08854166666666662, recall = 0.008173148419895481.\n",
            "Training on epoch 61 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.08901098901098899, recall = 0.006462272487179205.\n",
            "\n",
            "Training on 61 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08599999999999992, recall = 0.007462131281355307.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08849999999999997, recall = 0.00771584788395212.\n",
            "\n",
            "Training on the 62 epoch\n",
            "Training on epoch 62 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09166666666666666, recall = 0.0058244324131433425.\n",
            "Training on epoch 62 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.09042553191489358, recall = 0.007610837973458329.\n",
            "Training on epoch 62 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09263157894736838, recall = 0.008802400618232627.\n",
            "Training on epoch 62 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.07888888888888884, recall = 0.007212357708291381.\n",
            "Training on epoch 62 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.10416666666666664, recall = 0.009465301080682957.\n",
            "Training on epoch 62 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09099999999999996, recall = 0.006675267627245293.\n",
            "Training on epoch 62 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08791208791208789, recall = 0.006882572047253093.\n",
            "Training on epoch 62 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09157894736842102, recall = 0.007528320630981977.\n",
            "\n",
            "Training on 62 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08749999999999995, recall = 0.007458839878152283.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08849999999999997, recall = 0.00771584788395212.\n",
            "\n",
            "Training on the 63 epoch\n",
            "Training on epoch 63 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.09569892473118276, recall = 0.009537239223941368.\n",
            "Training on epoch 63 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.07684210526315788, recall = 0.006487037241148401.\n",
            "Training on epoch 63 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.08762886597938141, recall = 0.0077590804662431455.\n",
            "Training on epoch 63 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09361702127659573, recall = 0.00559438551521293.\n",
            "Training on epoch 63 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.08599999999999994, recall = 0.006481802164248601.\n",
            "Training on epoch 63 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08936170212765956, recall = 0.0063272305794583785.\n",
            "Training on epoch 63 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
            " Top K precision = 0.08020833333333327, recall = 0.007523604503191808.\n",
            "Training on epoch 63 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.07395833333333333, recall = 0.007904289177080037.\n",
            "\n",
            "Training on 63 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08900000000000001, recall = 0.007558772127474775.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08949999999999995, recall = 0.007575778930195866.\n",
            "\n",
            "Training on the 64 epoch\n",
            "Training on epoch 64 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09560439560439558, recall = 0.00864995988502241.\n",
            "Training on epoch 64 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.10235294117647054, recall = 0.009608463767897821.\n",
            "Training on epoch 64 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08085106382978721, recall = 0.006827412824837665.\n",
            "Training on epoch 64 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09247311827956987, recall = 0.007691141307245241.\n",
            "Training on epoch 64 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.09565217391304345, recall = 0.0075090481849771655.\n",
            "Training on epoch 64 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
            " Top K precision = 0.09888888888888887, recall = 0.00799466537218905.\n",
            "Training on epoch 64 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09999999999999994, recall = 0.008869124415905549.\n",
            "Training on epoch 64 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.7e-05.\n",
            " Top K precision = 0.10107526881720424, recall = 0.008464483591252788.\n",
            "\n",
            "Training on 64 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999986, recall = 0.007558772127474776.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08649999999999995, recall = 0.007410923664150398.\n",
            "\n",
            "Training on the 65 epoch\n",
            "Training on epoch 65 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08080808080808079, recall = 0.007818520523896692.\n",
            "Training on epoch 65 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09117647058823525, recall = 0.007567893173948812.\n",
            "Training on epoch 65 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.7e-05.\n",
            " Top K precision = 0.10421052631578938, recall = 0.009513853805227108.\n",
            "Training on epoch 65 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 9e-06.\n",
            " Top K precision = 0.09893617021276593, recall = 0.008516235361541148.\n",
            "Training on epoch 65 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09659090909090907, recall = 0.008874881494562538.\n",
            "Training on epoch 65 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.6e-05.\n",
            " Top K precision = 0.09176470588235291, recall = 0.008428279334116813.\n",
            "Training on epoch 65 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.09072164948453604, recall = 0.007719444026316141.\n",
            "Training on epoch 65 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08854166666666663, recall = 0.007210183144901807.\n",
            "\n",
            "Training on 65 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08799999999999994, recall = 0.007443538559884864.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08349999999999995, recall = 0.007201205507358761.\n",
            "\n",
            "Training on the 66 epoch\n",
            "Training on epoch 66 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.08461538461538459, recall = 0.006373627308358553.\n",
            "Training on epoch 66 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08817204301075267, recall = 0.006845129777829183.\n",
            "Training on epoch 66 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09374999999999999, recall = 0.008052042038540694.\n",
            "Training on epoch 66 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09895833333333331, recall = 0.005628212694073063.\n",
            "Training on epoch 66 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09090909090909086, recall = 0.006526114826727457.\n",
            "Training on epoch 66 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
            " Top K precision = 0.09699999999999996, recall = 0.008020209313456766.\n",
            "Training on epoch 66 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
            " Top K precision = 0.09186046511627903, recall = 0.00720867298910151.\n",
            "Training on epoch 66 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.10103092783505149, recall = 0.009151656766063576.\n",
            "\n",
            "Training on 66 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999998, recall = 0.00755877212747478.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08599999999999994, recall = 0.007570125270967878.\n",
            "\n",
            "Training on the 67 epoch\n",
            "Training on epoch 67 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693155, and regularization loss is 8e-06.\n",
            " Top K precision = 0.09130434782608692, recall = 0.006893207076561285.\n",
            "Training on epoch 67 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.10618556701030926, recall = 0.007316931861625956.\n",
            "Training on epoch 67 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.0958762886597938, recall = 0.007635091826397952.\n",
            "Training on epoch 67 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.10099009900990091, recall = 0.008833458890860155.\n",
            "Training on epoch 67 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.07959183673469383, recall = 0.007522543284715466.\n",
            "Training on epoch 67 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.08526315789473682, recall = 0.008995065589870977.\n",
            "Training on epoch 67 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08737864077669902, recall = 0.008111212805916493.\n",
            "Training on epoch 67 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.06382978723404253, recall = 0.0057680417540002535.\n",
            "\n",
            "Training on 67 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08900000000000002, recall = 0.007553246700614935.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08349999999999995, recall = 0.007201205507358761.\n",
            "\n",
            "Training on the 68 epoch\n",
            "Training on epoch 68 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09550561797752807, recall = 0.006757011863551368.\n",
            "Training on epoch 68 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.0894736842105263, recall = 0.007334954836733444.\n",
            "Training on epoch 68 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08842105263157891, recall = 0.007175822540258856.\n",
            "Training on epoch 68 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08620689655172409, recall = 0.007190585477089307.\n",
            "Training on epoch 68 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08602150537634407, recall = 0.006852480958913341.\n",
            "Training on epoch 68 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09787234042553188, recall = 0.0070301978280705325.\n",
            "Training on epoch 68 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09450549450549445, recall = 0.007745480350542164.\n",
            "Training on epoch 68 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08387096774193545, recall = 0.008103652536781858.\n",
            "\n",
            "Training on 68 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08649999999999991, recall = 0.007334951089185793.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08949999999999995, recall = 0.007575778930195866.\n",
            "\n",
            "Training on the 69 epoch\n",
            "Training on epoch 69 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.09175257731958758, recall = 0.00882870304419983.\n",
            "Training on epoch 69 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08777777777777777, recall = 0.006137969031698871.\n",
            "Training on epoch 69 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08383838383838381, recall = 0.007467186657865572.\n",
            "Training on epoch 69 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08791208791208788, recall = 0.006964215367232697.\n",
            "Training on epoch 69 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.10531914893617018, recall = 0.009488287888689212.\n",
            "Training on epoch 69 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.07446808510638298, recall = 0.007123366450409729.\n",
            "Training on epoch 69 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09555555555555545, recall = 0.009534726602020711.\n",
            "Training on epoch 69 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
            " Top K precision = 0.08936170212765958, recall = 0.00845676184958075.\n",
            "\n",
            "Training on 69 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08799999999999995, recall = 0.007494270717154547.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08799999999999995, recall = 0.00753976072063067.\n",
            "\n",
            "Training on the 70 epoch\n",
            "Training on epoch 70 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.07857142857142853, recall = 0.008352912123132878.\n",
            "Training on epoch 70 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.1031249999999999, recall = 0.007934276403636057.\n",
            "Training on epoch 70 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08969072164948451, recall = 0.008300347842633615.\n",
            "Training on epoch 70 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.06947368421052631, recall = 0.006091072591091462.\n",
            "Training on epoch 70 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.10229885057471262, recall = 0.00789960671756694.\n",
            "Training on epoch 70 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.08229166666666664, recall = 0.006947981233104426.\n",
            "Training on epoch 70 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.09062499999999996, recall = 0.008584223589171202.\n",
            "Training on epoch 70 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.0909090909090909, recall = 0.007596725052461003.\n",
            "\n",
            "Training on 70 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999991, recall = 0.007561094484989207.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 71 epoch\n",
            "Training on epoch 71 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.07826086956521737, recall = 0.007006815715795906.\n",
            "Training on epoch 71 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.11224489795918362, recall = 0.008507319178882373.\n",
            "Training on epoch 71 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08510638297872339, recall = 0.007647500730470882.\n",
            "Training on epoch 71 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09399999999999993, recall = 0.009483105036303462.\n",
            "Training on epoch 71 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.07634408602150534, recall = 0.006061426962816225.\n",
            "Training on epoch 71 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.09148936170212761, recall = 0.00614716850645626.\n",
            "Training on epoch 71 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.07419354838709678, recall = 0.005967562249621881.\n",
            "Training on epoch 71 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08695652173913039, recall = 0.008543123292431447.\n",
            "\n",
            "Training on 71 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08749999999999995, recall = 0.007422717705706069.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 72 epoch\n",
            "Training on epoch 72 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.07849462365591393, recall = 0.006671089869795271.\n",
            "Training on epoch 72 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.08260869565217392, recall = 0.008252397144138234.\n",
            "Training on epoch 72 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.0848484848484848, recall = 0.00694361075243657.\n",
            "Training on epoch 72 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08021978021978021, recall = 0.006388847912598672.\n",
            "Training on epoch 72 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.10344827586206895, recall = 0.010339021718842609.\n",
            "Training on epoch 72 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.08936170212765952, recall = 0.007252623637765824.\n",
            "Training on epoch 72 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08936170212765954, recall = 0.008332684630600265.\n",
            "Training on epoch 72 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08602150537634409, recall = 0.007125876819885603.\n",
            "\n",
            "Training on 72 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08849999999999997, recall = 0.00746948641318906.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08949999999999995, recall = 0.007575778930195866.\n",
            "\n",
            "Training on the 73 epoch\n",
            "Training on epoch 73 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.09010989010989008, recall = 0.0074503854115623115.\n",
            "Training on epoch 73 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09175257731958758, recall = 0.0076212693138076335.\n",
            "Training on epoch 73 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.08775510204081632, recall = 0.006749080420943058.\n",
            "Training on epoch 73 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.0945652173913043, recall = 0.006551848781645315.\n",
            "Training on epoch 73 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09896907216494841, recall = 0.008081473646701375.\n",
            "Training on epoch 73 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09101123595505617, recall = 0.007581683725181335.\n",
            "Training on epoch 73 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09479166666666666, recall = 0.008462089043925347.\n",
            "Training on epoch 73 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.07346938775510203, recall = 0.007313721707541122.\n",
            "\n",
            "Training on 73 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08649999999999995, recall = 0.007394488846333485.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.07899999999999992, recall = 0.007176540441286666.\n",
            "\n",
            "Training on the 74 epoch\n",
            "Training on epoch 74 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.08514851485148511, recall = 0.007140956473928116.\n",
            "Training on epoch 74 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.09684210526315787, recall = 0.0081233905448701.\n",
            "Training on epoch 74 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09021739130434779, recall = 0.006974916363937819.\n",
            "Training on epoch 74 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09081632653061221, recall = 0.008801516337451092.\n",
            "Training on epoch 74 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08888888888888886, recall = 0.007905745433386499.\n",
            "Training on epoch 74 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09134615384615383, recall = 0.006719316234612915.\n",
            "Training on epoch 74 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08446601941747567, recall = 0.008764318505457176.\n",
            "Training on epoch 74 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.08699999999999998, recall = 0.007294514281618638.\n",
            "\n",
            "Training on 74 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08799999999999994, recall = 0.007510181262557382.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08349999999999995, recall = 0.007201205507358761.\n",
            "\n",
            "Training on the 75 epoch\n",
            "Training on epoch 75 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693177, and regularization loss is 3e-05.\n",
            " Top K precision = 0.08041237113402058, recall = 0.00554398830910708.\n",
            "Training on epoch 75 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.08541666666666665, recall = 0.008009708868466645.\n",
            "Training on epoch 75 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08461538461538458, recall = 0.007309221113073948.\n",
            "Training on epoch 75 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.69318, and regularization loss is 3.3e-05.\n",
            " Top K precision = 0.09468085106382976, recall = 0.006422754323322906.\n",
            "Training on epoch 75 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693177, and regularization loss is 2.9e-05.\n",
            " Top K precision = 0.09578947368421048, recall = 0.00648969946869257.\n",
            "Training on epoch 75 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09166666666666663, recall = 0.00827934688980547.\n",
            "Training on epoch 75 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.090625, recall = 0.007431735969904162.\n",
            "Training on epoch 75 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08775510204081631, recall = 0.0069770910466562175.\n",
            "\n",
            "Training on 75 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.0885, recall = 0.007524758522032601.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08849999999999997, recall = 0.007507751719311511.\n",
            "\n",
            "Training on the 76 epoch\n",
            "Training on epoch 76 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.0904255319148936, recall = 0.006380205033745844.\n",
            "Training on epoch 76 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08695652173913046, recall = 0.006297188302208629.\n",
            "Training on epoch 76 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09191919191919191, recall = 0.007852747465451566.\n",
            "Training on epoch 76 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08571428571428566, recall = 0.0056199054639312395.\n",
            "Training on epoch 76 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.0914893617021276, recall = 0.008398850052477562.\n",
            "Training on epoch 76 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08888888888888882, recall = 0.00863772380956126.\n",
            "Training on epoch 76 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
            " Top K precision = 0.08144329896907213, recall = 0.00655343535509802.\n",
            "Training on epoch 76 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.6e-05.\n",
            " Top K precision = 0.09523809523809522, recall = 0.008053376054734543.\n",
            "\n",
            "Training on 76 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999995, recall = 0.007558772127474776.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08949999999999995, recall = 0.007575778930195866.\n",
            "\n",
            "Training on the 77 epoch\n",
            "Training on epoch 77 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.0833333333333333, recall = 0.006341472577249132.\n",
            "Training on epoch 77 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.10204081632653056, recall = 0.007901623596462203.\n",
            "Training on epoch 77 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09891304347826084, recall = 0.008508380750112761.\n",
            "Training on epoch 77 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.08390804597701149, recall = 0.0065947791824926.\n",
            "Training on epoch 77 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08282828282828278, recall = 0.0073078531516808645.\n",
            "Training on epoch 77 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09111111111111109, recall = 0.008662492525463573.\n",
            "Training on epoch 77 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.10217391304347821, recall = 0.007176429417368379.\n",
            "Training on epoch 77 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.0989361702127659, recall = 0.007477665326711324.\n",
            "\n",
            "Training on 77 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.0885, recall = 0.0075247585220326.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08849999999999997, recall = 0.00771584788395212.\n",
            "\n",
            "Training on the 78 epoch\n",
            "Training on epoch 78 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09494949494949488, recall = 0.007761558609341417.\n",
            "Training on epoch 78 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.07613636363636361, recall = 0.007079115717942203.\n",
            "Training on epoch 78 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.5e-05.\n",
            " Top K precision = 0.09223300970873781, recall = 0.008685251243525384.\n",
            "Training on epoch 78 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.10439560439560436, recall = 0.007920657550947884.\n",
            "Training on epoch 78 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.10624999999999997, recall = 0.00825939898619293.\n",
            "Training on epoch 78 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09052631578947365, recall = 0.007844304882074691.\n",
            "Training on epoch 78 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693176, and regularization loss is 2.9e-05.\n",
            " Top K precision = 0.08387096774193546, recall = 0.008667612036933876.\n",
            "Training on epoch 78 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.08725490196078427, recall = 0.006965055178435764.\n",
            "\n",
            "Training on 78 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08799999999999994, recall = 0.007443538559884863.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08349999999999995, recall = 0.007201205507358761.\n",
            "\n",
            "Training on the 79 epoch\n",
            "Training on epoch 79 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09204545454545454, recall = 0.006606074080066266.\n",
            "Training on epoch 79 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.10340909090909087, recall = 0.009371212221306558.\n",
            "Training on epoch 79 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
            " Top K precision = 0.08585858585858584, recall = 0.0063944268190195995.\n",
            "Training on epoch 79 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 9e-06.\n",
            " Top K precision = 0.0872549019607843, recall = 0.0068575184170257064.\n",
            "Training on epoch 79 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.08842105263157891, recall = 0.00860724670599756.\n",
            "Training on epoch 79 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09032258064516126, recall = 0.006930483372829108.\n",
            "Training on epoch 79 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.0928571428571428, recall = 0.0076986807916287646.\n",
            "Training on epoch 79 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.09191919191919189, recall = 0.009333486933617782.\n",
            "\n",
            "Training on 79 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08799999999999991, recall = 0.007456731311148247.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08649999999999995, recall = 0.007410923664150398.\n",
            "\n",
            "Training on the 80 epoch\n",
            "Training on epoch 80 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09374999999999996, recall = 0.009365159520446217.\n",
            "Training on epoch 80 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.08333333333333331, recall = 0.005718697479332249.\n",
            "Training on epoch 80 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.1021276595744681, recall = 0.00783935455841628.\n",
            "Training on epoch 80 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.09111111111111109, recall = 0.007326623569629291.\n",
            "Training on epoch 80 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.08064516129032256, recall = 0.007308843561308376.\n",
            "Training on epoch 80 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.07499999999999997, recall = 0.006271012060438679.\n",
            "Training on epoch 80 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09578947368421052, recall = 0.008690317125302242.\n",
            "Training on epoch 80 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.08571428571428569, recall = 0.007787728837809848.\n",
            "\n",
            "Training on 80 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08599999999999994, recall = 0.007428405926806709.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 81 epoch\n",
            "Training on epoch 81 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.08924731182795698, recall = 0.0061198214213475065.\n",
            "Training on epoch 81 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.07528089887640449, recall = 0.007498459911806984.\n",
            "Training on epoch 81 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.10645161290322579, recall = 0.00717668715838132.\n",
            "Training on epoch 81 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08041237113402061, recall = 0.005769981181459842.\n",
            "Training on epoch 81 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09489795918367337, recall = 0.007640871477215278.\n",
            "Training on epoch 81 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.07777777777777775, recall = 0.0067483985763270105.\n",
            "Training on epoch 81 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.08703703703703701, recall = 0.007677795743705219.\n",
            "Training on epoch 81 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.4e-05.\n",
            " Top K precision = 0.07628865979381441, recall = 0.006726400100278809.\n",
            "\n",
            "Training on 81 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08749999999999995, recall = 0.0073947602871843494.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08949999999999995, recall = 0.007575778930195866.\n",
            "\n",
            "Training on the 82 epoch\n",
            "Training on epoch 82 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.09263157894736841, recall = 0.008130395293956217.\n",
            "Training on epoch 82 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.08823529411764702, recall = 0.007759329215905737.\n",
            "Training on epoch 82 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.08989898989898985, recall = 0.008423986839039698.\n",
            "Training on epoch 82 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.07659574468085105, recall = 0.007273467289721247.\n",
            "Training on epoch 82 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.0908163265306122, recall = 0.008310491049271352.\n",
            "Training on epoch 82 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08260869565217388, recall = 0.006216538644472735.\n",
            "Training on epoch 82 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.09130434782608694, recall = 0.007809714705026344.\n",
            "Training on epoch 82 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.0789473684210526, recall = 0.0065448180089524854.\n",
            "\n",
            "Training on 82 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999995, recall = 0.007558772127474773.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 83 epoch\n",
            "Training on epoch 83 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.09900990099009896, recall = 0.008066067736764895.\n",
            "Training on epoch 83 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09687499999999995, recall = 0.009762377934440054.\n",
            "Training on epoch 83 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.07474747474747472, recall = 0.006572153933600956.\n",
            "Training on epoch 83 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.07282608695652175, recall = 0.0067598474653035555.\n",
            "Training on epoch 83 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.10227272727272728, recall = 0.008741397150502424.\n",
            "Training on epoch 83 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.0975903614457831, recall = 0.007448799630318365.\n",
            "Training on epoch 83 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.69318, and regularization loss is 3.3e-05.\n",
            " Top K precision = 0.0917525773195876, recall = 0.00751562012801582.\n",
            "Training on epoch 83 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.0824175824175824, recall = 0.006050310025703112.\n",
            "\n",
            "Training on 83 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08849999999999993, recall = 0.007524758522032597.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08649999999999995, recall = 0.007410923664150398.\n",
            "\n",
            "Training on the 84 epoch\n",
            "Training on epoch 84 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.6e-05.\n",
            " Top K precision = 0.10957446808510635, recall = 0.008256441116589418.\n",
            "Training on epoch 84 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.08804347826086956, recall = 0.007633684361881708.\n",
            "Training on epoch 84 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08229166666666665, recall = 0.007030926061165073.\n",
            "Training on epoch 84 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09574468085106382, recall = 0.006671805751048839.\n",
            "Training on epoch 84 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09157894736842097, recall = 0.006992961801197771.\n",
            "Training on epoch 84 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.6e-05.\n",
            " Top K precision = 0.0978021978021978, recall = 0.00779940221574832.\n",
            "Training on epoch 84 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08811881188118807, recall = 0.006901167934285304.\n",
            "Training on epoch 84 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09010989010989008, recall = 0.007697518828308152.\n",
            "\n",
            "Training on 84 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08349999999999995, recall = 0.007201205507358761.\n",
            "\n",
            "Training on the 85 epoch\n",
            "Training on epoch 85 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.0933333333333333, recall = 0.008048334819643822.\n",
            "Training on epoch 85 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.11914893617021276, recall = 0.010049165906192231.\n",
            "Training on epoch 85 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09529411764705882, recall = 0.0072946585557183245.\n",
            "Training on epoch 85 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.5e-05.\n",
            " Top K precision = 0.06702127659574467, recall = 0.005354334997875554.\n",
            "Training on epoch 85 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.0736842105263158, recall = 0.006549178884874068.\n",
            "Training on epoch 85 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.10196078431372542, recall = 0.008742464529598717.\n",
            "Training on epoch 85 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08144329896907213, recall = 0.00750093587092288.\n",
            "Training on epoch 85 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.08817204301075268, recall = 0.007431634198315454.\n",
            "\n",
            "Training on 85 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999997, recall = 0.007558772127474776.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08749999999999995, recall = 0.007696836477108015.\n",
            "\n",
            "Training on the 86 epoch\n",
            "Training on epoch 86 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09690721649484532, recall = 0.00729961396414986.\n",
            "Training on epoch 86 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.07894736842105263, recall = 0.005933351584938129.\n",
            "Training on epoch 86 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.11249999999999999, recall = 0.008112764895672047.\n",
            "Training on epoch 86 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08350515463917524, recall = 0.0072682337481419865.\n",
            "Training on epoch 86 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 2e-05.\n",
            " Top K precision = 0.07604166666666663, recall = 0.007453038989840254.\n",
            "Training on epoch 86 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.09560439560439558, recall = 0.0078811469163272.\n",
            "Training on epoch 86 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.07444444444444441, recall = 0.006938586897562417.\n",
            "Training on epoch 86 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.0838383838383838, recall = 0.007055697432461969.\n",
            "\n",
            "Training on 86 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08700000000000001, recall = 0.007401971661610007.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08849999999999997, recall = 0.007545035863738513.\n",
            "\n",
            "Training on the 87 epoch\n",
            "Training on epoch 87 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.09659090909090905, recall = 0.008256557439073988.\n",
            "Training on epoch 87 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09081632653061225, recall = 0.00787578823233938.\n",
            "Training on epoch 87 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.08314606741573032, recall = 0.008135520492064908.\n",
            "Training on epoch 87 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.0882978723404255, recall = 0.00833486824873128.\n",
            "Training on epoch 87 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08399999999999996, recall = 0.00726256679523205.\n",
            "Training on epoch 87 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.10102040816326525, recall = 0.008655367734954941.\n",
            "Training on epoch 87 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08571428571428572, recall = 0.007827659760718725.\n",
            "Training on epoch 87 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.08989898989898987, recall = 0.007166820892366639.\n",
            "\n",
            "Training on 87 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08749999999999995, recall = 0.007333720242313931.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08949999999999995, recall = 0.007575778930195866.\n",
            "\n",
            "Training on the 88 epoch\n",
            "Training on epoch 88 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693175, and regularization loss is 2.8e-05.\n",
            " Top K precision = 0.09462365591397848, recall = 0.007792275502964931.\n",
            "Training on epoch 88 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09484536082474222, recall = 0.007228550805636548.\n",
            "Training on epoch 88 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.10416666666666662, recall = 0.010191856670230629.\n",
            "Training on epoch 88 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.09999999999999994, recall = 0.007726339958082271.\n",
            "Training on epoch 88 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09680851063829785, recall = 0.008013207496093694.\n",
            "Training on epoch 88 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
            " Top K precision = 0.10219780219780217, recall = 0.007789789355162499.\n",
            "Training on epoch 88 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08659793814432987, recall = 0.008744755736020252.\n",
            "Training on epoch 88 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09239130434782607, recall = 0.00793408996083413.\n",
            "\n",
            "Training on 88 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999993, recall = 0.007558772127474773.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08799999999999995, recall = 0.00753976072063067.\n",
            "\n",
            "Training on the 89 epoch\n",
            "Training on epoch 89 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.0938775510204081, recall = 0.007331569813974744.\n",
            "Training on epoch 89 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08494623655913976, recall = 0.008331142017336231.\n",
            "Training on epoch 89 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.07333333333333333, recall = 0.006754916051104002.\n",
            "Training on epoch 89 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.10490196078431364, recall = 0.009105469113474483.\n",
            "Training on epoch 89 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09038461538461537, recall = 0.007594986300632724.\n",
            "Training on epoch 89 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08777777777777777, recall = 0.007399726633954699.\n",
            "Training on epoch 89 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.07613636363636361, recall = 0.007847217360602527.\n",
            "Training on epoch 89 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.091578947368421, recall = 0.008711550866378632.\n",
            "\n",
            "Training on 89 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999995, recall = 0.007558772127474777.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08949999999999995, recall = 0.007575778930195866.\n",
            "\n",
            "Training on the 90 epoch\n",
            "Training on epoch 90 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08297872340425531, recall = 0.008393321928033966.\n",
            "Training on epoch 90 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.10294117647058816, recall = 0.008428754951232773.\n",
            "Training on epoch 90 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693171, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.08526315789473682, recall = 0.006743884668866402.\n",
            "Training on epoch 90 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09374999999999996, recall = 0.007417604761451078.\n",
            "Training on epoch 90 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.10645161290322576, recall = 0.009199993422529433.\n",
            "Training on epoch 90 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.5e-05.\n",
            " Top K precision = 0.09893617021276589, recall = 0.007541284563949376.\n",
            "Training on epoch 90 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08571428571428572, recall = 0.0058361054564588025.\n",
            "Training on epoch 90 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09797979797979797, recall = 0.006938992788783635.\n",
            "\n",
            "Training on 90 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999993, recall = 0.007558772127474776.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 91 epoch\n",
            "Training on epoch 91 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.08111111111111108, recall = 0.0072122622519707824.\n",
            "Training on epoch 91 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.6e-05.\n",
            " Top K precision = 0.10208333333333329, recall = 0.0072072412349936665.\n",
            "Training on epoch 91 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09687499999999993, recall = 0.008924639109434928.\n",
            "Training on epoch 91 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.08469387755102038, recall = 0.006359858262170439.\n",
            "Training on epoch 91 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08999999999999998, recall = 0.006614659014515912.\n",
            "Training on epoch 91 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09677419354838705, recall = 0.008061208540811386.\n",
            "Training on epoch 91 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.07938144329896903, recall = 0.006367626201470289.\n",
            "Training on epoch 91 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09347826086956518, recall = 0.0064886576439224485.\n",
            "\n",
            "Training on 91 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08649999999999994, recall = 0.007430729744443822.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08449999999999992, recall = 0.007347611278915881.\n",
            "\n",
            "Training on the 92 epoch\n",
            "Training on epoch 92 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693176, and regularization loss is 2.9e-05.\n",
            " Top K precision = 0.1010526315789473, recall = 0.007292306027273366.\n",
            "Training on epoch 92 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.09705882352941171, recall = 0.008544432103816741.\n",
            "Training on epoch 92 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.08144329896907215, recall = 0.005453261793579982.\n",
            "Training on epoch 92 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09659090909090907, recall = 0.007959155018827572.\n",
            "Training on epoch 92 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.08599999999999997, recall = 0.008619345746061864.\n",
            "Training on epoch 92 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09230769230769226, recall = 0.007465889907803625.\n",
            "Training on epoch 92 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693173, and regularization loss is 2.5e-05.\n",
            " Top K precision = 0.08105263157894732, recall = 0.008276511077997073.\n",
            "Training on epoch 92 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693168, and regularization loss is 2e-05.\n",
            " Top K precision = 0.09361702127659573, recall = 0.007808494806303115.\n",
            "\n",
            "Training on 92 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08849999999999998, recall = 0.0075247585220326015.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 93 epoch\n",
            "Training on epoch 93 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09784946236559133, recall = 0.007697949323596785.\n",
            "Training on epoch 93 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.08181818181818179, recall = 0.008178985424563981.\n",
            "Training on epoch 93 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.10315789473684203, recall = 0.007888997115372061.\n",
            "Training on epoch 93 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.10631578947368418, recall = 0.009364147500862124.\n",
            "Training on epoch 93 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08124999999999998, recall = 0.007576328187757564.\n",
            "Training on epoch 93 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693156, and regularization loss is 9e-06.\n",
            " Top K precision = 0.09381443298969068, recall = 0.006369567773750954.\n",
            "Training on epoch 93 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.09782608695652172, recall = 0.006764847246588716.\n",
            "Training on epoch 93 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693177, and regularization loss is 3e-05.\n",
            " Top K precision = 0.07419354838709676, recall = 0.0066596190996952315.\n",
            "\n",
            "Training on 93 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999993, recall = 0.007558772127474773.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08849999999999997, recall = 0.00771584788395212.\n",
            "\n",
            "Training on the 94 epoch\n",
            "Training on epoch 94 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.09489795918367348, recall = 0.007995425137185307.\n",
            "Training on epoch 94 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693162, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09673913043478259, recall = 0.008731338152312225.\n",
            "Training on epoch 94 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.08131868131868131, recall = 0.007486004704765515.\n",
            "Training on epoch 94 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.07234042553191489, recall = 0.005728972810750918.\n",
            "Training on epoch 94 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.08571428571428566, recall = 0.007386927684063464.\n",
            "Training on epoch 94 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.09347826086956519, recall = 0.008599802433687903.\n",
            "Training on epoch 94 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1e-05.\n",
            " Top K precision = 0.09191919191919191, recall = 0.007614700322932099.\n",
            "Training on epoch 94 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.10206185567010306, recall = 0.008581388886051644.\n",
            "\n",
            "Training on 94 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 95 epoch\n",
            "Training on epoch 95 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693179, and regularization loss is 3.1e-05.\n",
            " Top K precision = 0.09393939393939389, recall = 0.007743262632478765.\n",
            "Training on epoch 95 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.09892473118279566, recall = 0.007264430884846804.\n",
            "Training on epoch 95 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.09166666666666666, recall = 0.006519540324153013.\n",
            "Training on epoch 95 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693172, and regularization loss is 2.4e-05.\n",
            " Top K precision = 0.09215686274509798, recall = 0.007851536674751655.\n",
            "Training on epoch 95 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.07916666666666668, recall = 0.005510415837638388.\n",
            "Training on epoch 95 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08571428571428565, recall = 0.007833700447833096.\n",
            "Training on epoch 95 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.09354838709677414, recall = 0.0070218880038949456.\n",
            "Training on epoch 95 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09230769230769226, recall = 0.008553086967148238.\n",
            "\n",
            "Training on 95 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08799999999999995, recall = 0.007464520661340858.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08799999999999995, recall = 0.00753976072063067.\n",
            "\n",
            "Training on the 96 epoch\n",
            "Training on epoch 96 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.09574468085106382, recall = 0.0061182903466843975.\n",
            "Training on epoch 96 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693165, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.08222222222222221, recall = 0.005843967087054059.\n",
            "Training on epoch 96 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.07899999999999999, recall = 0.006513543831306142.\n",
            "Training on epoch 96 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.5e-05.\n",
            " Top K precision = 0.08068181818181817, recall = 0.008672956789627788.\n",
            "Training on epoch 96 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.1e-05.\n",
            " Top K precision = 0.09583333333333331, recall = 0.007880274503049576.\n",
            "Training on epoch 96 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693164, and regularization loss is 1.7e-05.\n",
            " Top K precision = 0.09099999999999998, recall = 0.007888242146805512.\n",
            "Training on epoch 96 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09670329670329665, recall = 0.008270042102890748.\n",
            "Training on epoch 96 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.1063829787234042, recall = 0.010114740864332963.\n",
            "\n",
            "Training on 96 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999995, recall = 0.007558772127474779.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08949999999999995, recall = 0.007575778930195866.\n",
            "\n",
            "Training on the 97 epoch\n",
            "Training on epoch 97 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09680851063829785, recall = 0.008619470439683348.\n",
            "Training on epoch 97 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.08947368421052627, recall = 0.007206396686032801.\n",
            "Training on epoch 97 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693158, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.07582417582417583, recall = 0.006616207183727354.\n",
            "Training on epoch 97 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693157, and regularization loss is 1e-05.\n",
            " Top K precision = 0.09239130434782605, recall = 0.007199290283911297.\n",
            "Training on epoch 97 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.07157894736842102, recall = 0.007667462721119618.\n",
            "Training on epoch 97 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.693175, and regularization loss is 2.8e-05.\n",
            " Top K precision = 0.09591836734693875, recall = 0.008305517190181345.\n",
            "Training on epoch 97 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.06808510638297868, recall = 0.005989443160780368.\n",
            "Training on epoch 97 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.8e-05.\n",
            " Top K precision = 0.10549450549450544, recall = 0.008267755845071664.\n",
            "\n",
            "Training on 97 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08900000000000001, recall = 0.007841640906907128.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08299999999999993, recall = 0.007199200903235744.\n",
            "\n",
            "Training on the 98 epoch\n",
            "Training on epoch 98 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08437499999999998, recall = 0.006797955079406163.\n",
            "Training on epoch 98 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.10412371134020616, recall = 0.008385045700852994.\n",
            "Training on epoch 98 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.4e-05.\n",
            " Top K precision = 0.0989010989010989, recall = 0.007180752690926088.\n",
            "Training on epoch 98 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693174, and regularization loss is 2.7e-05.\n",
            " Top K precision = 0.09255319148936167, recall = 0.008781388748495064.\n",
            "Training on epoch 98 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.1e-05.\n",
            " Top K precision = 0.10439560439560434, recall = 0.00799188314456972.\n",
            "Training on epoch 98 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.69316, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.09670329670329665, recall = 0.007057059638945208.\n",
            "Training on epoch 98 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693167, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.08383838383838381, recall = 0.007521602354161499.\n",
            "Training on epoch 98 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.693163, and regularization loss is 1.6e-05.\n",
            " Top K precision = 0.0824175824175824, recall = 0.006046432774189649.\n",
            "\n",
            "Training on 98 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08849999999999998, recall = 0.007515668679198912.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n",
            "Training on the 99 epoch\n",
            "Training on epoch 99 minibatch 1/782 completed\n",
            " bpr_loss on current minibatch is 0.693161, and regularization loss is 1.3e-05.\n",
            " Top K precision = 0.09120879120879116, recall = 0.008015843442879391.\n",
            "Training on epoch 99 minibatch 101/782 completed\n",
            " bpr_loss on current minibatch is 0.693182, and regularization loss is 3.4e-05.\n",
            " Top K precision = 0.08444444444444443, recall = 0.008885710731779118.\n",
            "Training on epoch 99 minibatch 201/782 completed\n",
            " bpr_loss on current minibatch is 0.693159, and regularization loss is 1.2e-05.\n",
            " Top K precision = 0.08437499999999999, recall = 0.0059007501628216144.\n",
            "Training on epoch 99 minibatch 301/782 completed\n",
            " bpr_loss on current minibatch is 0.693169, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.08999999999999994, recall = 0.0071753525335696835.\n",
            "Training on epoch 99 minibatch 401/782 completed\n",
            " bpr_loss on current minibatch is 0.693166, and regularization loss is 1.9e-05.\n",
            " Top K precision = 0.09789473684210521, recall = 0.008014586639899127.\n",
            "Training on epoch 99 minibatch 501/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.2e-05.\n",
            " Top K precision = 0.09456521739130429, recall = 0.008587620859870627.\n",
            "Training on epoch 99 minibatch 601/782 completed\n",
            " bpr_loss on current minibatch is 0.693175, and regularization loss is 2.8e-05.\n",
            " Top K precision = 0.08723404255319146, recall = 0.005998260265775021.\n",
            "Training on epoch 99 minibatch 701/782 completed\n",
            " bpr_loss on current minibatch is 0.69317, and regularization loss is 2.3e-05.\n",
            " Top K precision = 0.07311827956989245, recall = 0.006729614644205009.\n",
            "\n",
            "Training on 99 epoch completed.\n",
            " Average bpr_loss on train set is 0.005421 for the current epoch.\n",
            " Training top K precision = 0.08899999999999997, recall = 0.0076780961728824095.\n",
            " Average bpr_loss on the validation set is 7e-06, and regularization loss is 0.0.\n",
            " Validation top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epochs_tracked, [precision for precision, _ in train_topks],\n",
        "         label=\"Train\")\n",
        "plt.plot(epochs_tracked, [precision for precision, _ in val_topks],\n",
        "         label=\"Val\")\n",
        "plt.ylabel(f\"Top {K} precision\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "iNzstdupmKCT",
        "outputId": "2800ff44-467e-46bb-d9ab-15a9d11d48c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epochs_tracked, [recall for _, recall in train_topks],\n",
        "         label=\"Train\")\n",
        "plt.plot(epochs_tracked, [recall for _, recall in val_topks],\n",
        "         label=\"Val\")\n",
        "plt.ylabel(f\"Top {K} recall\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "VprdTh7GmMvX",
        "outputId": "a046ae57-11b1-4eef-b402-b8600b9c455e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict on the test set\n",
        "lightGCN.eval()\n",
        "print(\"Training completed after {} epochs\".format(epochs))\n",
        "\n",
        "users_test = samples_test[:, 0:1]\n",
        "pos_test = samples_test[:, 1:2]\n",
        "neg_test = samples_test[:, 2:3]\n",
        "\n",
        "loss_test, reg_loss_test = bpr_loss(\n",
        "    lightGCN, users_test, pos_test, neg_test, data, test_mask)\n",
        "reg_loss_test = reg_loss_test * weight_decay\n",
        "\n",
        "# predict on the test set\n",
        "user_indices = samples_test[:, 0]\n",
        "user_indices = user_indices.repeat(2).long()\n",
        "item_indices = torch.cat((samples_test[:, 1], samples_test[:, 2])).long()\n",
        "pred_test = getUsersRating(lightGCN, users_test[:,0], data)\\\n",
        "    [user_indices, item_indices]\n",
        "truth_test = data[\"edge_index\"][users_test.long()[:,0]]\\\n",
        "    [user_indices, item_indices]\n",
        "test_topk_precision, test_topk_recall = personalized_topk(\n",
        "    pred_test, K, user_indices, data[\"edge_index\"])\n",
        "\n",
        "print(\"Average bpr_loss on the test set is {}, and regularization loss is {}.\\n\".format(round(float((loss_test+reg_loss_test)/len(samples_test)), 6),\n",
        "                                                                                                round(float(reg_loss_test/len(samples_test)), 6)),\n",
        "      \"Top K precision = {}, recall = {}.\".format(test_topk_precision, test_topk_recall))\n",
        "\n",
        "# Save model embeddings.\n",
        "torch.save(lightGCN, config_dict[\"model_name\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaoXw2MwmPlX",
        "outputId": "dec2bfb6-cfc1-456b-9271-5c9978bee512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed after 100 epochs\n",
            "Average bpr_loss on the test set is 7e-06, and regularization loss is 0.0.\n",
            " Top K precision = 0.08899999999999995, recall = 0.0075587721274747765.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def matrix_factorization(user_item, rank):\n",
        "    \"\"\"Phân tích nhân tử ma trận trên user_item và nhận các điểm tương đồng giữa user-item.\n",
        "\n",
        "    Args:\n",
        "        user_item: User-item connectivity matrix.\n",
        "        rank: Number of numbers to represent a user / item.\n",
        "\n",
        "    Returns:\n",
        "        User-item similarities.\n",
        "    \"\"\"\n",
        "    weights, (user_factors, item_factors) = \\\n",
        "        decomposition.parafac(user_item, rank)\n",
        "    similarities = user_factors @ item_factors.T\n",
        "    return 1 / (1 + np.exp(- similarities))"
      ],
      "metadata": {
        "id": "rjCOlIqEmYG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute baseline metrics using matrix factorization.\n",
        "baseline_pred = matrix_factorization(\n",
        "        data[\"edge_index\"].detach().cpu().numpy(),\n",
        "        config_dict[\"mf_rank\"])[user_indices.cpu(), item_indices.cpu()]\n",
        "baseline_topk_precision, baseline_topk_recall = \\\n",
        "        personalized_topk(baseline_pred, K, user_indices, data[\"edge_index\"])\n",
        "print(\"Baseline (PARAFAC matrix factorization) produces \",\n",
        "      \"Top K precision = {}, recall = {}.\".format(baseline_topk_precision,\n",
        "                                                  baseline_topk_recall))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vf-ar6L0madP",
        "outputId": "d9fa08fa-a1ec-402c-f1b6-aa2c62d09544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline (PARAFAC matrix factorization) produces  Top K precision = 0.038, recall = 0.00294577867812301.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -10 /content/raw/ml-1m/ratings.dat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Dn7QVDzuo35",
        "outputId": "c03e71b7-4f6a-4175-de89-ecf14aca2069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1::1193::5::978300760\n",
            "1::661::3::978302109\n",
            "1::914::3::978301968\n",
            "1::3408::4::978300275\n",
            "1::2355::5::978824291\n",
            "1::1197::3::978302268\n",
            "1::1287::5::978302039\n",
            "1::2804::5::978300719\n",
            "1::594::4::978302268\n",
            "1::919::4::978301368\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -100000 /content/raw/ml-1m/README"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cxf3YI4Smiyi",
        "outputId": "e3665582-7c53-4058-e18a-86389893c9f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUMMARY\n",
            "================================================================================\n",
            "\n",
            "These files contain 1,000,209 anonymous ratings of approximately 3,900 movies \n",
            "made by 6,040 MovieLens users who joined MovieLens in 2000.\n",
            "\n",
            "USAGE LICENSE\n",
            "================================================================================\n",
            "\n",
            "Neither the University of Minnesota nor any of the researchers\n",
            "involved can guarantee the correctness of the data, its suitability\n",
            "for any particular purpose, or the validity of results based on the\n",
            "use of the data set.  The data set may be used for any research\n",
            "purposes under the following conditions:\n",
            "\n",
            "     * The user may not state or imply any endorsement from the\n",
            "       University of Minnesota or the GroupLens Research Group.\n",
            "\n",
            "     * The user must acknowledge the use of the data set in\n",
            "       publications resulting from the use of the data set\n",
            "       (see below for citation information).\n",
            "\n",
            "     * The user may not redistribute the data without separate\n",
            "       permission.\n",
            "\n",
            "     * The user may not use this information for any commercial or\n",
            "       revenue-bearing purposes without first obtaining permission\n",
            "       from a faculty member of the GroupLens Research Project at the\n",
            "       University of Minnesota.\n",
            "\n",
            "If you have any further questions or comments, please contact GroupLens\n",
            "<grouplens-info@cs.umn.edu>. \n",
            "\n",
            "CITATION\n",
            "================================================================================\n",
            "\n",
            "To acknowledge use of the dataset in publications, please cite the following\n",
            "paper:\n",
            "\n",
            "F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History\n",
            "and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4,\n",
            "Article 19 (December 2015), 19 pages. DOI=http://dx.doi.org/10.1145/2827872\n",
            "\n",
            "\n",
            "ACKNOWLEDGEMENTS\n",
            "================================================================================\n",
            "\n",
            "Thanks to Shyong Lam and Jon Herlocker for cleaning up and generating the data\n",
            "set.\n",
            "\n",
            "FURTHER INFORMATION ABOUT THE GROUPLENS RESEARCH PROJECT\n",
            "================================================================================\n",
            "\n",
            "The GroupLens Research Project is a research group in the Department of \n",
            "Computer Science and Engineering at the University of Minnesota. Members of \n",
            "the GroupLens Research Project are involved in many research projects related \n",
            "to the fields of information filtering, collaborative filtering, and \n",
            "recommender systems. The project is lead by professors John Riedl and Joseph \n",
            "Konstan. The project began to explore automated collaborative filtering in \n",
            "1992, but is most well known for its world wide trial of an automated \n",
            "collaborative filtering system for Usenet news in 1996. Since then the project \n",
            "has expanded its scope to research overall information filtering solutions, \n",
            "integrating in content-based methods as well as improving current collaborative \n",
            "filtering technology.\n",
            "\n",
            "Further information on the GroupLens Research project, including research \n",
            "publications, can be found at the following web site:\n",
            "        \n",
            "        http://www.grouplens.org/\n",
            "\n",
            "GroupLens Research currently operates a movie recommender based on \n",
            "collaborative filtering:\n",
            "\n",
            "        http://www.movielens.org/\n",
            "\n",
            "RATINGS FILE DESCRIPTION\n",
            "================================================================================\n",
            "\n",
            "All ratings are contained in the file \"ratings.dat\" and are in the\n",
            "following format:\n",
            "\n",
            "UserID::MovieID::Rating::Timestamp\n",
            "\n",
            "- UserIDs range between 1 and 6040 \n",
            "- MovieIDs range between 1 and 3952\n",
            "- Ratings are made on a 5-star scale (whole-star ratings only)\n",
            "- Timestamp is represented in seconds since the epoch as returned by time(2)\n",
            "- Each user has at least 20 ratings\n",
            "\n",
            "USERS FILE DESCRIPTION\n",
            "================================================================================\n",
            "\n",
            "User information is in the file \"users.dat\" and is in the following\n",
            "format:\n",
            "\n",
            "UserID::Gender::Age::Occupation::Zip-code\n",
            "\n",
            "All demographic information is provided voluntarily by the users and is\n",
            "not checked for accuracy.  Only users who have provided some demographic\n",
            "information are included in this data set.\n",
            "\n",
            "- Gender is denoted by a \"M\" for male and \"F\" for female\n",
            "- Age is chosen from the following ranges:\n",
            "\n",
            "\t*  1:  \"Under 18\"\n",
            "\t* 18:  \"18-24\"\n",
            "\t* 25:  \"25-34\"\n",
            "\t* 35:  \"35-44\"\n",
            "\t* 45:  \"45-49\"\n",
            "\t* 50:  \"50-55\"\n",
            "\t* 56:  \"56+\"\n",
            "\n",
            "- Occupation is chosen from the following choices:\n",
            "\n",
            "\t*  0:  \"other\" or not specified\n",
            "\t*  1:  \"academic/educator\"\n",
            "\t*  2:  \"artist\"\n",
            "\t*  3:  \"clerical/admin\"\n",
            "\t*  4:  \"college/grad student\"\n",
            "\t*  5:  \"customer service\"\n",
            "\t*  6:  \"doctor/health care\"\n",
            "\t*  7:  \"executive/managerial\"\n",
            "\t*  8:  \"farmer\"\n",
            "\t*  9:  \"homemaker\"\n",
            "\t* 10:  \"K-12 student\"\n",
            "\t* 11:  \"lawyer\"\n",
            "\t* 12:  \"programmer\"\n",
            "\t* 13:  \"retired\"\n",
            "\t* 14:  \"sales/marketing\"\n",
            "\t* 15:  \"scientist\"\n",
            "\t* 16:  \"self-employed\"\n",
            "\t* 17:  \"technician/engineer\"\n",
            "\t* 18:  \"tradesman/craftsman\"\n",
            "\t* 19:  \"unemployed\"\n",
            "\t* 20:  \"writer\"\n",
            "\n",
            "MOVIES FILE DESCRIPTION\n",
            "================================================================================\n",
            "\n",
            "Movie information is in the file \"movies.dat\" and is in the following\n",
            "format:\n",
            "\n",
            "MovieID::Title::Genres\n",
            "\n",
            "- Titles are identical to titles provided by the IMDB (including\n",
            "year of release)\n",
            "- Genres are pipe-separated and are selected from the following genres:\n",
            "\n",
            "\t* Action\n",
            "\t* Adventure\n",
            "\t* Animation\n",
            "\t* Children's\n",
            "\t* Comedy\n",
            "\t* Crime\n",
            "\t* Documentary\n",
            "\t* Drama\n",
            "\t* Fantasy\n",
            "\t* Film-Noir\n",
            "\t* Horror\n",
            "\t* Musical\n",
            "\t* Mystery\n",
            "\t* Romance\n",
            "\t* Sci-Fi\n",
            "\t* Thriller\n",
            "\t* War\n",
            "\t* Western\n",
            "\n",
            "- Some MovieIDs do not correspond to a movie due to accidental duplicate\n",
            "entries and/or test entries\n",
            "- Movies are mostly entered by hand, so errors and inconsistencies may exist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WRxFdh0Zzpex"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}